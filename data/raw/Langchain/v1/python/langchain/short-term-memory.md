# çŸ­æœŸè®°å¿†

## æ¦‚è§ˆ (Overview)

**è®°å¿†**æ˜¯ä¸€ä¸ªç³»ç»Ÿï¼Œç”¨äºŽè®°ä½å…³äºŽå…ˆå‰äº¤äº’çš„ä¿¡æ¯ã€‚å¯¹äºŽ **AI ä»£ç†** (AI agents) è€Œè¨€ï¼Œè®°å¿†è‡³å…³é‡è¦ï¼Œå› ä¸ºå®ƒèƒ½è®©ä»–ä»¬è®°ä½ä¹‹å‰çš„äº¤äº’ã€ä»Žåé¦ˆä¸­å­¦ä¹ å¹¶é€‚åº”ç”¨æˆ·åå¥½ã€‚éšç€ä»£ç†å¤„ç†æ¶‰åŠå¤§é‡ç”¨æˆ·äº¤äº’çš„æ›´å¤æ‚ä»»åŠ¡ï¼Œè¿™ç§èƒ½åŠ›å¯¹äºŽ**æ•ˆçŽ‡**å’Œ**ç”¨æˆ·æ»¡æ„åº¦**éƒ½å˜å¾—è‡³å…³é‡è¦ã€‚

**çŸ­æœŸè®°å¿†**è®©æ‚¨çš„åº”ç”¨ç¨‹åºèƒ½å¤Ÿè®°ä½**å•ä¸ªçº¿ç¨‹**æˆ–**å¯¹è¯**ä¸­çš„å…ˆå‰äº¤äº’ã€‚

> ðŸ’¡ **æ³¨æ„ï¼š**
> ä¸€ä¸ªçº¿ç¨‹ (thread) åœ¨ä¸€ä¸ªä¼šè¯ (session) ä¸­ç»„ç»‡å¤šæ¬¡äº¤äº’ï¼Œç±»ä¼¼äºŽç”µå­é‚®ä»¶å°†æ¶ˆæ¯åˆ†ç»„åˆ°ä¸€ä¸ªå¯¹è¯ä¸­çš„æ–¹å¼ã€‚

**ä¼šè¯åŽ†å²è®°å½•** (Conversation history) æ˜¯çŸ­æœŸè®°å¿†æœ€å¸¸è§çš„å½¢å¼ã€‚å¯¹äºŽå½“ä»Šçš„ **LLM** (å¤§åž‹è¯­è¨€æ¨¡åž‹) æ¥è¯´ï¼Œ**é•¿å¯¹è¯**æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼›å®Œæ•´çš„åŽ†å²è®°å½•å¯èƒ½æ— æ³•å®Œå…¨å®¹çº³åœ¨ä¸€ä¸ª LLM çš„**ä¸Šä¸‹æ–‡çª—å£** (context window) å†…ï¼Œä»Žè€Œå¯¼è‡´**ä¸Šä¸‹æ–‡ä¸¢å¤±** (context loss) æˆ–**é”™è¯¯**ã€‚

å³ä½¿æ‚¨çš„æ¨¡åž‹æ”¯æŒå®Œæ•´çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œå¤§å¤šæ•° LLM åœ¨å¤„ç†**é•¿ä¸Šä¸‹æ–‡**æ—¶çš„è¡¨çŽ°ä»ç„¶ä¸ä½³ã€‚å®ƒä»¬ä¼šè¢«é™ˆæ—§æˆ–è·‘é¢˜çš„å†…å®¹â€œåˆ†å¿ƒâ€ï¼ŒåŒæ—¶è¿˜ä¼šå¯¼è‡´**å“åº”æ—¶é—´å˜æ…¢**å’Œ**æˆæœ¬æ›´é«˜**ã€‚

èŠå¤©æ¨¡åž‹ä½¿ç”¨ **æ¶ˆæ¯** (messages) æŽ¥å—ä¸Šä¸‹æ–‡ï¼Œè¿™äº›æ¶ˆæ¯åŒ…æ‹¬**æŒ‡ä»¤**ï¼ˆç³»ç»Ÿæ¶ˆæ¯ system messageï¼‰å’Œ**è¾“å…¥**ï¼ˆäººç±»æ¶ˆæ¯ human messagesï¼‰ã€‚åœ¨èŠå¤©åº”ç”¨ç¨‹åºä¸­ï¼Œæ¶ˆæ¯åœ¨äººç±»è¾“å…¥å’Œæ¨¡åž‹å“åº”ä¹‹é—´äº¤æ›¿ï¼Œå¯¼è‡´æ¶ˆæ¯åˆ—è¡¨éšç€æ—¶é—´æŽ¨ç§»è€Œå˜é•¿ã€‚ç”±äºŽä¸Šä¸‹æ–‡çª—å£æ˜¯æœ‰é™çš„ï¼Œè®¸å¤šåº”ç”¨ç¨‹åºå¯ä»¥å—ç›ŠäºŽä½¿ç”¨æŠ€æœ¯æ¥**ç§»é™¤**æˆ–**â€œé—å¿˜â€**é™ˆæ—§ä¿¡æ¯ã€‚

## ç”¨æ³• (Usage)

è¦å‘ä»£ç†æ·»åŠ çŸ­æœŸè®°å¿†ï¼ˆçº¿ç¨‹çº§æŒä¹…æ€§ï¼‰ï¼Œæ‚¨éœ€è¦åœ¨åˆ›å»ºä»£ç†æ—¶æŒ‡å®šä¸€ä¸ª **`checkpointer`**ã€‚

> â„¹ï¸ **ä¿¡æ¯ï¼š**
> LangChain çš„ä»£ç†å°†çŸ­æœŸè®°å¿†ä½œä¸ºä»£ç†**çŠ¶æ€** (state) çš„ä¸€éƒ¨åˆ†è¿›è¡Œç®¡ç†ã€‚
>
> é€šè¿‡å°†è¿™äº›å­˜å‚¨åœ¨å›¾ (graph) çš„çŠ¶æ€ä¸­ï¼Œä»£ç†å¯ä»¥è®¿é—®ç»™å®šå¯¹è¯çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶ä¿æŒä¸åŒçº¿ç¨‹ä¹‹é—´çš„åˆ†ç¦»ã€‚
>
> çŠ¶æ€ä½¿ç”¨ **checkpointer** æŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼ˆæˆ–å†…å­˜ï¼‰ä¸­ï¼Œä»¥ä¾¿çº¿ç¨‹å¯ä»¥éšæ—¶æ¢å¤ã€‚
>
> å½“ä»£ç†è¢«è°ƒç”¨æˆ–ä¸€ä¸ªæ­¥éª¤ï¼ˆå¦‚å·¥å…·è°ƒç”¨ï¼‰å®Œæˆæ—¶ï¼ŒçŸ­æœŸè®°å¿†ä¼šæ›´æ–°ï¼Œå¹¶åœ¨æ¯ä¸ªæ­¥éª¤å¼€å§‹æ—¶è¯»å–çŠ¶æ€ã€‚

```python
from langchain.agents import create_agent
from langgraph.checkpoint.memory import InMemorySaver  # [!code highlight]
agent = create_agent(
    "openai:gpt-5",
    [get_user_info],
    checkpointer=InMemorySaver(),  # [!code highlight]
)
agent.invoke(
    {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]},
    {"configurable": {"thread_id": "1"}},  # [!code highlight]
)
```

#### ç”Ÿäº§çŽ¯å¢ƒ (In production)

åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­ï¼Œè¯·ä½¿ç”¨ç”±**æ•°æ®åº“**æ”¯æŒçš„ checkpointerï¼š

```shell
pip install langgraph-checkpoint-postgres
```

```python
from langchain.agents import create_agent
from langgraph.checkpoint.postgres import PostgresSaver  # [!code highlight]
DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"
with PostgresSaver.from_conn_string(DB_URI) as checkpointer:
    checkpointer.setup() # auto create tables in PostgresSql
    agent = create_agent(
        "openai:gpt-5",
        [get_user_info],
        checkpointer=checkpointer,  # [!code highlight]
    )
```

## è‡ªå®šä¹‰ä»£ç†è®°å¿† (Customizing agent memory)

é»˜è®¤æƒ…å†µä¸‹ï¼Œä»£ç†ä½¿ç”¨ **`AgentState`** æ¥ç®¡ç†çŸ­æœŸè®°å¿†ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ **`messages`** é”®æ¥ç®¡ç†ä¼šè¯åŽ†å²è®°å½•ã€‚

æ‚¨å¯ä»¥æ‰©å±• **`AgentState`** ä»¥æ·»åŠ é¢å¤–çš„å­—æ®µã€‚è‡ªå®šä¹‰çŠ¶æ€æ¨¡å¼é€šè¿‡ **`state_schema`** å‚æ•°ä¼ é€’ç»™ **`create_agent`**ã€‚

```python
from langchain.agents import create_agent, AgentState
from langgraph.checkpoint.memory import InMemorySaver
class CustomAgentState(AgentState):  # [!code highlight]
    user_id: str  # [!code highlight]
    preferences: dict  # [!code highlight]
agent = create_agent(
    "openai:gpt-5",
    [get_user_info],
    state_schema=CustomAgentState,  # [!code highlight]
    checkpointer=InMemorySaver(),
)
# Custom state can be passed in invoke
result = agent.invoke(
    {
        "messages": [{"role": "user", "content": "Hello"}],
        "user_id": "user_123",  # [!code highlight]
        "preferences": {"theme": "dark"}  # [!code highlight]
    },
    {"configurable": {"thread_id": "1"}})
```

## å¸¸è§æ¨¡å¼ (Common patterns)

å¯ç”¨**çŸ­æœŸè®°å¿†**åŽï¼Œé•¿å¯¹è¯å¯èƒ½ä¼šè¶…å‡º LLM çš„ä¸Šä¸‹æ–‡çª—å£ã€‚å¸¸è§çš„è§£å†³æ–¹æ¡ˆæœ‰ï¼š

| æ¨¡å¼ | æè¿° |
| :--- | :--- |
| **ä¿®å‰ªæ¶ˆæ¯** (Trim messages) âœ‚ï¸ | ç§»é™¤æœ€åˆæˆ–æœ€åŽçš„ N æ¡æ¶ˆæ¯ï¼ˆåœ¨è°ƒç”¨ LLM ä¹‹å‰ï¼‰ã€‚ |
| **åˆ é™¤æ¶ˆæ¯** (Delete messages) ðŸ—‘ï¸ | ä»Ž LangGraph çŠ¶æ€ä¸­**æ°¸ä¹…**åˆ é™¤æ¶ˆæ¯ã€‚ |
| **æ€»ç»“æ¶ˆæ¯** (Summarize messages) ðŸ“ | æ€»ç»“åŽ†å²è®°å½•ä¸­è¾ƒæ—©çš„æ¶ˆæ¯ï¼Œå¹¶ç”¨æ‘˜è¦æ›¿æ¢å®ƒä»¬ã€‚ |
| **è‡ªå®šä¹‰ç­–ç•¥** (Custom strategies) âš™ï¸ | è‡ªå®šä¹‰ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼šæ¶ˆæ¯è¿‡æ»¤ç­‰ï¼‰ã€‚ |

è¿™ä½¿å¾—ä»£ç†èƒ½å¤Ÿåœ¨ä¸è¶…å‡º LLM ä¸Šä¸‹æ–‡çª—å£çš„æƒ…å†µä¸‹è·Ÿè¸ªå¯¹è¯ã€‚

#### ä¿®å‰ªæ¶ˆæ¯ (Trim messages)

å¤§å¤šæ•° LLM éƒ½æœ‰ä¸€ä¸ªæœ€å¤§æ”¯æŒçš„ä¸Šä¸‹æ–‡çª—å£ï¼ˆä»¥ token è®¡ï¼‰ã€‚

å†³å®šä½•æ—¶æˆªæ–­æ¶ˆæ¯çš„ä¸€ç§æ–¹æ³•æ˜¯**è®¡ç®—æ¶ˆæ¯åŽ†å²è®°å½•ä¸­çš„ token æ•°**ï¼Œå¹¶åœ¨æŽ¥è¿‘è¯¥é™åˆ¶æ—¶è¿›è¡Œæˆªæ–­ã€‚å¦‚æžœæ‚¨ä½¿ç”¨ LangChainï¼Œå¯ä»¥ä½¿ç”¨**ä¿®å‰ªæ¶ˆæ¯å®žç”¨ç¨‹åº** (trim messages utility) å¹¶æŒ‡å®šè¦ä»Žåˆ—è¡¨ä¸­ä¿ç•™çš„ token æ•°é‡ï¼Œä»¥åŠç”¨äºŽå¤„ç†è¾¹ç•Œçš„ `strategy`ï¼ˆä¾‹å¦‚ï¼šä¿ç•™æœ€åŽçš„ `max_tokens`ï¼‰ã€‚

è¦åœ¨ä»£ç†ä¸­ä¿®å‰ªæ¶ˆæ¯åŽ†å²è®°å½•ï¼Œè¯·ä½¿ç”¨ **`@before_model`** ä¸­é—´ä»¶è£…é¥°å™¨ï¼š

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig
from typing import Any
@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Keep only the last few messages to fit context window."""
    messages = state["messages"]
    if len(messages) <= 3:
        return None  # No changes needed
    first_msg = messages[0]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }
agent = create_agent(
    model,
    tools=tools,
    middleware=[trim_messages],
    checkpointer=InMemorySaver(),
)
config: RunnableConfig = {"configurable": {"thread_id": "1"}}
agent.invoke({"messages": "hi, my name is bob"}, config)
agent.invoke({"messages": "write a short poem about cats"}, config)
agent.invoke({"messages": "now do the same but for dogs"}, config)
final_response = agent.invoke({"messages": "what's my name?"}, config)
final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
Your name is Bob. You told me that earlier.
If you'd like me to call you a nickname or use a different name, just say the word.
"""
```

#### åˆ é™¤æ¶ˆæ¯ (Delete messages)

æ‚¨å¯ä»¥ä»Žå›¾çŠ¶æ€ä¸­åˆ é™¤æ¶ˆæ¯ä»¥ç®¡ç†æ¶ˆæ¯åŽ†å²è®°å½•ã€‚

å½“æ‚¨æƒ³è¦åˆ é™¤ç‰¹å®šæ¶ˆæ¯æˆ–æ¸…é™¤æ•´ä¸ªæ¶ˆæ¯åŽ†å²è®°å½•æ—¶ï¼Œè¿™éžå¸¸æœ‰ç”¨ã€‚

è¦ä»Žå›¾çŠ¶æ€ä¸­åˆ é™¤æ¶ˆæ¯ï¼Œå¯ä»¥ä½¿ç”¨ **`RemoveMessage`**ã€‚

è¦ä½¿ `RemoveMessage` å·¥ä½œï¼Œæ‚¨éœ€è¦ä½¿ç”¨å…·æœ‰ **`add_messages`** [reducer] çš„çŠ¶æ€é”®ã€‚

é»˜è®¤çš„ **`AgentState`** æä¾›äº†æ­¤åŠŸèƒ½ã€‚

åˆ é™¤**ç‰¹å®š**æ¶ˆæ¯ï¼š

```python
from langchain.messages import RemoveMessage  # [!code highlight]
def delete_messages(state):
    messages = state["messages"]
    if len(messages) > 2:
        # remove the earliest two messages
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  # [!code highlight]
```

åˆ é™¤**æ‰€æœ‰**æ¶ˆæ¯ï¼š

```python
from langgraph.graph.message import REMOVE_ALL_MESSAGES  # [!code highlight]
def delete_messages(state):
    return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  # [!code highlight]
```

> âš ï¸ **è­¦å‘Šï¼š**
> åˆ é™¤æ¶ˆæ¯æ—¶ï¼Œ**è¯·ç¡®ä¿**ç”Ÿæˆçš„æ¶ˆæ¯åŽ†å²è®°å½•æ˜¯**æœ‰æ•ˆ**çš„ã€‚è¯·æ£€æŸ¥æ‚¨æ­£åœ¨ä½¿ç”¨çš„ LLM æä¾›å•†çš„é™åˆ¶ã€‚ä¾‹å¦‚ï¼š
>
> *   ä¸€äº›æä¾›å•†æœŸæœ›æ¶ˆæ¯åŽ†å²è®°å½•ä»¥ `user` æ¶ˆæ¯å¼€å§‹
> *   å¤§å¤šæ•°æä¾›å•†è¦æ±‚å¸¦æœ‰å·¥å…·è°ƒç”¨çš„ `assistant` æ¶ˆæ¯åŽè·Ÿç›¸åº”çš„ `tool` ç»“æžœæ¶ˆæ¯ã€‚

```python
from langchain.messages import RemoveMessage
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.runtime import Runtime
from langchain_core.runnables import RunnableConfig
@after_model
def delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None:
    """Remove old messages to keep conversation manageable."""
    messages = state["messages"]
    if len(messages) > 2:
        # remove the earliest two messages
        return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}
    return None
agent = create_agent(
    "openai:gpt-5-nano",
    tools=[],
    system_prompt="Please be concise and to the point.",
    middleware=[delete_old_messages],
    checkpointer=InMemorySaver(),
)
config: RunnableConfig = {"configurable": {"thread_id": "1"}}
for event in agent.stream(
    {"messages": [{"role": "user", "content": "hi! I'm bob"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])
for event in agent.stream(
    {"messages": [{"role": "user", "content": "what's my name?"}]},
    config,
    stream_mode="values",
):
    print([(message.type, message.content) for message in event["messages"]])
```

```
[('human', "hi! I'm bob")]
[('human', "hi! I'm bob"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.')]
[('human', "hi! I'm bob"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', "what's my name?")]
[('human', "hi! I'm bob"), ('ai', 'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.'), ('human', "what's my name?"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]
[('human', "what's my name?"), ('ai', 'Your name is Bob. How can I help you today, Bob?')]
```

#### æ€»ç»“æ¶ˆæ¯ (Summarize messages)

å¦‚ä¸Šæ‰€ç¤ºï¼Œä¿®å‰ªæˆ–åˆ é™¤æ¶ˆæ¯çš„é—®é¢˜æ˜¯æ‚¨å¯èƒ½ä¼šå› ä¸ºåˆ é™¤æ¶ˆæ¯é˜Ÿåˆ—è€Œ**ä¸¢å¤±ä¿¡æ¯**ã€‚
å› æ­¤ï¼Œä¸€äº›åº”ç”¨ç¨‹åºå—ç›ŠäºŽä½¿ç”¨**èŠå¤©æ¨¡åž‹**æ¥æ€»ç»“æ¶ˆæ¯åŽ†å²è®°å½•çš„æ›´å¤æ‚æ–¹æ³•ã€‚

è¦åœ¨ä»£ç†ä¸­æ€»ç»“æ¶ˆæ¯åŽ†å²è®°å½•ï¼Œè¯·ä½¿ç”¨å†…ç½®çš„ **`SummarizationMiddleware`**ï¼š

```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langchain_core.runnables import RunnableConfig
checkpointer = InMemorySaver()
agent = create_agent(
    model="openai:gpt-4o",
    tools=[],
    middleware=[
        SummarizationMiddleware(
            model="openai:gpt-4o-mini",
            max_tokens_before_summary=4000,  # Trigger summarization at 4000 tokens
            messages_to_keep=20,  # Keep last 20 messages after summary
        )
    ],
    checkpointer=checkpointer,
)
config: RunnableConfig = {"configurable": {"thread_id": "1"}}
agent.invoke({"messages": "hi, my name is bob"}, config)
agent.invoke({"messages": "write a short poem about cats"}, config)
agent.invoke({"messages": "now do the same but for dogs"}, config)
final_response = agent.invoke({"messages": "what's my name?"}, config)
final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
Your name is Bob!
"""
```

è¯·å‚é˜… `SummarizationMiddleware` äº†è§£æ›´å¤šé…ç½®é€‰é¡¹ã€‚

## è®¿é—®è®°å¿† (Access memory)

æ‚¨å¯ä»¥é€šè¿‡å‡ ç§æ–¹å¼è®¿é—®å’Œä¿®æ”¹ä»£ç†çš„çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ï¼š

#### å·¥å…· (Tools)

##### åœ¨å·¥å…·ä¸­è¯»å–çŸ­æœŸè®°å¿† (Read short-term memory in a tool)

ä½¿ç”¨ **`ToolRuntime`** å‚æ•°åœ¨å·¥å…·ä¸­è®¿é—®çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ã€‚

`tool_runtime` å‚æ•°å¯¹å·¥å…·ç­¾åæ˜¯**éšè—**çš„ï¼ˆå› æ­¤æ¨¡åž‹çœ‹ä¸åˆ°å®ƒï¼‰ï¼Œä½†å·¥å…·å¯ä»¥é€šè¿‡å®ƒè®¿é—®çŠ¶æ€ã€‚

```python
from langchain.agents import create_agent, AgentState
from langchain.tools import tool, ToolRuntime
class CustomState(AgentState):
    user_id: str
@tool
def get_user_info(
    runtime: ToolRuntime
) -> str:
    """Look up user info."""
    user_id = runtime.state["user_id"]
    return "User is John Smith" if user_id == "user_123" else "Unknown user"
agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[get_user_info],
    state_schema=CustomState,
)
result = agent.invoke({
    "messages": "look up user information",
    "user_id": "user_123"
})
print(result["messages"][-1].content)
# > User is John Smith.
```

##### ä»Žå·¥å…·å†™å…¥çŸ­æœŸè®°å¿† (Write short-term memory from tools)

è¦åœ¨æ‰§è¡ŒæœŸé—´ä¿®æ”¹ä»£ç†çš„çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ï¼Œæ‚¨å¯ä»¥ç›´æŽ¥ä»Žå·¥å…·è¿”å›ž**çŠ¶æ€æ›´æ–°** (state updates)ã€‚

è¿™å¯¹äºŽæŒä¹…åŒ–ä¸­é—´ç»“æžœæˆ–ä½¿ä¿¡æ¯å¯ä¾›åŽç»­å·¥å…·æˆ–æç¤ºè®¿é—®éžå¸¸æœ‰ç”¨ã€‚

```python
from langchain.tools import tool, ToolRuntime
from langchain_core.runnables import RunnableConfig
from langchain.messages import ToolMessage
from langchain.agents import create_agent, AgentState
from langgraph.types import Command
from pydantic import BaseModel
class CustomState(AgentState):  # [!code highlight]
    user_name: str
class CustomContext(BaseModel):
    user_id: str
@tool
def update_user_info(
    runtime: ToolRuntime[CustomContext, CustomState],
) -> Command:
    """Look up and update user info."""
    user_id = runtime.context.user_id  # [!code highlight]
    name = "John Smith" if user_id == "user_123" else "Unknown user"
    return Command(update={
        "user_name": name,
        # update the message history
        "messages": [
            ToolMessage(
                "Successfully looked up user information",
                tool_call_id=runtime.tool_call_id
            )
        ]
    })
@tool
def greet(
    runtime: ToolRuntime[CustomContext, CustomState]
) -> str:
    """Use this to greet the user once you found their info."""
    user_name = runtime.state["user_name"]
    return f"Hello {user_name}!"
  # [!code highlight]
agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[update_user_info, greet],
    state_schema=CustomState,
    context_schema=CustomContext,  # [!code highlight]
)
agent.invoke(
    {"messages": [{"role": "user", "content": "greet the user"}]},
    context=CustomContext(user_id="user_123"),
)
```

#### æç¤º (Prompt)

åœ¨**ä¸­é—´ä»¶** (middleware) ä¸­è®¿é—®çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥åŸºäºŽå¯¹è¯åŽ†å²è®°å½•æˆ–è‡ªå®šä¹‰çŠ¶æ€å­—æ®µåˆ›å»º**åŠ¨æ€æç¤º** (dynamic prompts)ã€‚

```python
from langchain.messages import AnyMessage
from langchain.agents import create_agent, AgentState
from typing import TypedDict
class CustomContext(TypedDict):
    user_name: str
from langchain.agents.middleware import dynamic_prompt, ModelRequest
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is always sunny!"
@dynamic_prompt
def dynamic_system_prompt(request: ModelRequest) -> str:
    user_name = request.runtime.context["user_name"]
    system_prompt = f"You are a helpful assistant. Address the user as {user_name}."
    return system_prompt
agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[get_weather],
    middleware=[dynamic_system_prompt],
    context_schema=CustomContext,
)
result = agent.invoke(
    {"messages": [{"role": "user", "content": "What is the weather in SF?"}]},
    context=CustomContext(user_name="John Smith"),
)
for msg in result["messages"]:
    msg.pretty_print()
```

**Output**

```shell
================================ Human Message =================================
What is the weather in SF?
================================== Ai Message ==================================
Tool Calls:
  get_weather (call_WFQlOGn4b2yoJrv7cih342FG)
  Call ID: call_WFQlOGn4b2yoJrv7cih342FG
  Args:
    city: San Francisco
================================= Tool Message =================================
Name: get_weather
The weather in San Francisco is always sunny!
================================== Ai Message ==================================
Hi John Smith, the weather in San Francisco is always sunny!
```

#### æ¨¡åž‹ä¹‹å‰ (Before model)

åœ¨ **`@before_model`** ä¸­é—´ä»¶ä¸­è®¿é—®çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥åœ¨æ¨¡åž‹è°ƒç”¨ä¹‹å‰å¤„ç†æ¶ˆæ¯ã€‚

```python
from langchain.messages import RemoveMessage
from langgraph.graph.message import REMOVE_ALL_MESSAGES
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import before_model
from langgraph.runtime import Runtime
from typing import Any
@before_model
def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Keep only the last few messages to fit context window."""
    messages = state["messages"]
    if len(messages) <= 3:
        return None  # No changes needed
    first_msg = messages[0]
    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]
    new_messages = [first_msg] + recent_messages
    return {
        "messages": [
            RemoveMessage(id=REMOVE_ALL_MESSAGES),
            *new_messages
        ]
    }
agent = create_agent(
    model,
    tools=tools,
    middleware=[trim_messages]
)
config: RunnableConfig = {"configurable": {"thread_id": "1"}}
agent.invoke({"messages": "hi, my name is bob"}, config)
agent.invoke({"messages": "write a short poem about cats"}, config)
agent.invoke({"messages": "now do the same but for dogs"}, config)
final_response = agent.invoke({"messages": "what's my name?"}, config)
final_response["messages"][-1].pretty_print()
"""
================================== Ai Message ==================================
Your name is Bob. You told me that earlier.
If you'd like me to call you a nickname or use a different name, just say the word.
"""
```

#### æ¨¡åž‹ä¹‹åŽ (After model)

åœ¨ **`@after_model`** ä¸­é—´ä»¶ä¸­è®¿é—®çŸ­æœŸè®°å¿†ï¼ˆçŠ¶æ€ï¼‰ï¼Œä»¥åœ¨æ¨¡åž‹è°ƒç”¨ä¹‹åŽå¤„ç†æ¶ˆæ¯ã€‚

```python
from langchain.messages import RemoveMessage
from langgraph.checkpoint.memory import InMemorySaver
from langchain.agents import create_agent, AgentState
from langchain.agents.middleware import after_model
from langgraph.runtime import Runtime
@after_model
def validate_response(state: AgentState, runtime: Runtime) -> dict | None:
    """Remove messages containing sensitive words."""
    STOP_WORDS = ["password", "secret"]
    last_message = state["messages"][-1]
    if any(word in last_message.content for word in STOP_WORDS):
        return {"messages": [RemoveMessage(id=last_message.id)]}
    return None
agent = create_agent(
    model="openai:gpt-5-nano",
    tools=[],
    middleware=[validate_response],
    checkpointer=InMemorySaver(),
)