# ä¸­é—´ä»¶

> æ§åˆ¶å¹¶å®šåˆ¶ä»£ç†ï¼ˆAgentï¼‰æ‰§è¡Œçš„æ¯ä¸€ä¸ªæ­¥éª¤

ä¸­é—´ä»¶æä¾›äº†ä¸€ç§æ–¹æ³•ï¼Œå¯ä»¥æ›´ç²¾ç»†åœ°æ§åˆ¶**ä»£ç†**ï¼ˆAgentï¼‰å†…éƒ¨çš„æ‰§è¡Œæµç¨‹ã€‚

æ ¸å¿ƒçš„ä»£ç†å¾ªç¯åŒ…æ‹¬è°ƒç”¨æ¨¡å‹ã€è®©æ¨¡å‹é€‰æ‹©å¹¶æ‰§è¡Œå·¥å…·ï¼Œç„¶ååœ¨æ¨¡å‹ä¸å†è°ƒç”¨å·¥å…·æ—¶ç»“æŸï¼š

![core_agent_loop.png](../../../assets/32a3019492d8bea54118f33fb56c6295.png)

ä¸­é—´ä»¶åœ¨è¿™äº›æ­¥éª¤çš„**ä¹‹å‰**å’Œ**ä¹‹å**æš´éœ²äº†é’©å­ (hooks)ï¼š

![middleware_final.png](../../../assets/bbd85e9df317d62ce9cd8a12bd4e9cf1.png)

## ä¸­é—´ä»¶å¯ä»¥åšä»€ä¹ˆï¼Ÿ

*   **ç›‘æ§ (Monitor)**
    è¿½è¸ªä»£ç†è¡Œä¸ºï¼ŒåŒ…æ‹¬æ—¥å¿—è®°å½•ã€åˆ†æå’Œè°ƒè¯•ã€‚
*   **ä¿®æ”¹ (Modify)**
    è½¬æ¢æç¤ºè¯ï¼ˆpromptsï¼‰ã€å·¥å…·é€‰æ‹©å’Œè¾“å‡ºæ ¼å¼ã€‚
*   **æ§åˆ¶ (Control)**
    æ·»åŠ é‡è¯•ã€å›é€€å’Œæå‰ç»ˆæ­¢é€»è¾‘ã€‚
*   **å¼ºåˆ¶æ‰§è¡Œ (Enforce)**
    åº”ç”¨é€Ÿç‡é™åˆ¶ã€å®‰å…¨é˜²æŠ¤ï¼ˆguardrailsï¼‰å’Œä¸ªäººèº«ä»½ä¿¡æ¯ï¼ˆPIIï¼‰æ£€æµ‹ã€‚

é€šè¿‡å°†å…¶ä¼ é€’ç»™ `create_agent` å‡½æ•°æ¥æ·»åŠ ä¸­é—´ä»¶ï¼š

```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware, HumanInTheLoopMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[SummarizationMiddleware(), HumanInTheLoopMiddleware()],
)
```

## é¢„ç½®ä¸­é—´ä»¶ (Built-in middleware)

LangChain ä¸ºå¸¸è§ç”¨ä¾‹æä¾›äº†é¢„æ„å»ºçš„ä¸­é—´ä»¶ï¼š

### æ‘˜è¦ (Summarization)

åœ¨æ¥è¿‘**ä¸Šä¸‹æ–‡çª—å£**ï¼ˆtoken limitsï¼‰é™åˆ¶æ—¶ï¼Œè‡ªåŠ¨å¯¹å¯¹è¯å†å²è¿›è¡Œæ‘˜è¦ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   è¶…è¿‡ä¸Šä¸‹æ–‡çª—å£çš„**é•¿æœŸå¯¹è¯**
> *   å…·æœ‰å¤§é‡å†å²è®°å½•çš„**å¤šè½®å¯¹è¯**
> *   éœ€è¦ä¿ç•™å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡çš„åº”ç”¨

```python
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[weather_tool, calculator_tool],
    middleware=[
        SummarizationMiddleware(
            model="openai:gpt-4o-mini",
            max_tokens_before_summary=4000,  # åœ¨ 4000 ä¸ª token æ—¶è§¦å‘æ‘˜è¦
            messages_to_keep=20,  # æ‘˜è¦åä¿ç•™æœ€è¿‘ 20 æ¡æ¶ˆæ¯
            summary_prompt="Custom prompt for summarization...",  # å¯é€‰
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `model`: **å­—ç¬¦ä¸²**ï¼Œç”¨äºç”Ÿæˆæ‘˜è¦çš„æ¨¡å‹ã€‚
*   `max_tokens_before_summary`: **æ•°å­—**ï¼Œè§¦å‘æ‘˜è¦çš„ token é˜ˆå€¼ã€‚
*   `messages_to_keep`: **æ•°å­— (é»˜è®¤å€¼: 20)**ï¼Œè¦ä¿ç•™çš„æœ€æ–°æ¶ˆæ¯æ•°é‡ã€‚
*   `token_counter`: **å‡½æ•°**ï¼Œè‡ªå®šä¹‰ token è®¡æ•°å‡½æ•°ã€‚é»˜è®¤ä¸ºåŸºäºå­—ç¬¦çš„è®¡æ•°ã€‚
*   `summary_prompt`: **å­—ç¬¦ä¸²**ï¼Œè‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨å†…ç½®æ¨¡æ¿ã€‚
*   `summary_prefix`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "## Previous conversation summary:")**ï¼Œæ‘˜è¦æ¶ˆæ¯çš„å‰ç¼€ã€‚

### äººåœ¨å›è·¯ä¸­ (Human-in-the-loop)

åœ¨å·¥å…·æ‰§è¡Œä¹‹å‰ï¼Œæš‚åœä»£ç†æ‰§è¡Œä»¥ä¾›äººå·¥æ‰¹å‡†ã€ç¼–è¾‘æˆ–æ‹’ç»å·¥å…·è°ƒç”¨ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   éœ€è¦äººå·¥æ‰¹å‡†çš„**é«˜é£é™©æ“ä½œ**ï¼ˆæ•°æ®åº“å†™å…¥ã€é‡‘èäº¤æ˜“ï¼‰
> *   å¼ºåˆ¶è¦æ±‚äººå·¥ç›‘ç£çš„**åˆè§„å·¥ä½œæµ**
> *   ä½¿ç”¨äººå·¥åé¦ˆæ¥æŒ‡å¯¼ä»£ç†çš„**é•¿æœŸå¯¹è¯**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langgraph.checkpoint.memory import InMemorySaver
agent = create_agent(
    model="openai:gpt-4o",
    tools=[read_email_tool, send_email_tool],
    checkpointer=InMemorySaver(),
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                # è¦æ±‚å¯¹å‘é€é‚®ä»¶è¿›è¡Œæ‰¹å‡†ã€ç¼–è¾‘æˆ–æ‹’ç»
                "send_email_tool": {
                    "allowed_decisions": ["approve", "edit", "reject"],
                },
                # è‡ªåŠ¨æ‰¹å‡†è¯»å–é‚®ä»¶
                "read_email_tool": False,
            }
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `interrupt_on`: **å­—å…¸ (å¿…éœ€)**ï¼Œå·¥å…·åç§°åˆ°æ‰¹å‡†é…ç½®çš„æ˜ å°„ã€‚å€¼å¯ä»¥æ˜¯ `True`ï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ä¸­æ–­ï¼‰ã€`False`ï¼ˆè‡ªåŠ¨æ‰¹å‡†ï¼‰æˆ–ä¸€ä¸ª `InterruptOnConfig` å¯¹è±¡ã€‚
*   `description_prefix`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "Tool execution requires approval")**ï¼Œæ“ä½œè¯·æ±‚æè¿°çš„å‰ç¼€ã€‚

**`InterruptOnConfig` é€‰é¡¹ï¼š**

*   `allowed_decisions`: **å­—ç¬¦ä¸²åˆ—è¡¨**ï¼Œå…è®¸çš„å†³å®šåˆ—è¡¨ï¼š`"approve"`ã€`"edit"` æˆ– `"reject"`ã€‚
*   `description`: **å­—ç¬¦ä¸² | å¯è°ƒç”¨å¯¹è±¡**ï¼Œç”¨äºè‡ªå®šä¹‰æè¿°çš„é™æ€å­—ç¬¦ä¸²æˆ–å¯è°ƒç”¨å‡½æ•°ã€‚

> **âš ï¸ é‡è¦æç¤ºï¼š** â€œäººåœ¨å›è·¯ä¸­â€ä¸­é—´ä»¶éœ€è¦ä¸€ä¸ª**æ£€æŸ¥ç‚¹**ï¼ˆcheckpointerï¼‰æ¥åœ¨ä¸­æ–­æœŸé—´ç»´æŠ¤çŠ¶æ€ã€‚

### ç¼“å­˜ (Anthropic prompt caching)

é€šè¿‡ä½¿ç”¨ Anthropic æ¨¡å‹ï¼Œç¼“å­˜é‡å¤çš„æç¤ºè¯å‰ç¼€ä»¥é™ä½æˆæœ¬ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   å…·æœ‰**å†—é•¿ã€é‡å¤ç³»ç»Ÿæç¤ºè¯**çš„åº”ç”¨
> *   åœ¨å¤šæ¬¡è°ƒç”¨ä¸­**é‡ç”¨ç›¸åŒä¸Šä¸‹æ–‡**çš„ä»£ç†
> *   ä¸ºé«˜æµé‡éƒ¨ç½²**é™ä½ API æˆæœ¬**

> **â„¹ï¸ äº†è§£æ›´å¤šï¼š** è¯·å‚é˜… [Anthropic æç¤ºè¯ç¼“å­˜](https://docs.claude.com/en/docs/build-with-claude/prompt-caching#cache-limitations)ç­–ç•¥å’Œé™åˆ¶ã€‚

```python
from langchain_anthropic import ChatAnthropic
from langchain_anthropic.middleware import AnthropicPromptCachingMiddleware
from langchain.agents import create_agent
LONG_PROMPT = """
Please be a helpful assistant.
<Lots more context ...>
"""
agent = create_agent(
    model=ChatAnthropic(model="claude-sonnet-4-latest"),
    system_prompt=LONG_PROMPT,
    middleware=[AnthropicPromptCachingMiddleware(ttl="5m")],
)
# ç¼“å­˜å­˜å‚¨
agent.invoke({"messages": [HumanMessage("Hi, my name is Bob")]})
# ç¼“å­˜å‘½ä¸­ï¼Œç³»ç»Ÿæç¤ºè¯è¢«ç¼“å­˜
agent.invoke({"messages": [HumanMessage("What's my name?")]})
```

**é…ç½®é€‰é¡¹ï¼š**

*   `type`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "ephemeral")**ï¼Œç¼“å­˜ç±»å‹ã€‚ç›®å‰ä»…æ”¯æŒ `"ephemeral"`ã€‚
*   `ttl`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "5m")**ï¼Œç¼“å­˜å†…å®¹çš„å­˜æ´»æ—¶é—´ (Time to live)ã€‚æœ‰æ•ˆå€¼ï¼š`"5m"` æˆ– `"1h"`ã€‚
*   `min_messages_to_cache`: **æ•°å­— (é»˜è®¤å€¼: 0)**ï¼Œå¼€å§‹ç¼“å­˜ä¹‹å‰çš„æœ€å°æ¶ˆæ¯æ•°é‡ã€‚
*   `unsupported_model_behavior`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "warn")**ï¼Œä½¿ç”¨é Anthropic æ¨¡å‹æ—¶çš„è¡Œä¸ºã€‚é€‰é¡¹ï¼š`"ignore"`ã€`"warn"` æˆ– `"raise"`ã€‚

### é™åˆ¶æ¨¡å‹è°ƒç”¨ (Model call limit)

é™åˆ¶æ¨¡å‹è°ƒç”¨çš„æ¬¡æ•°ï¼Œä»¥é˜²æ­¢æ— é™å¾ªç¯æˆ–æˆæœ¬è¿‡é«˜ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   é˜²æ­¢**å¤±æ§ä»£ç†**è¿›è¡Œè¿‡å¤š API è°ƒç”¨
> *   åœ¨ç”Ÿäº§éƒ¨ç½²ä¸­**å¼ºåˆ¶æ‰§è¡Œæˆæœ¬æ§åˆ¶**
> *   åœ¨ç‰¹å®šè°ƒç”¨é¢„ç®—å†…**æµ‹è¯•ä»£ç†è¡Œä¸º**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ModelCallLimitMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[
        ModelCallLimitMiddleware(
            thread_limit=10,  # æ¯ä¸ªçº¿ç¨‹ï¼ˆè·¨å¤šæ¬¡è¿è¡Œï¼‰æœ€å¤š 10 æ¬¡è°ƒç”¨
            run_limit=5,  # æ¯æ¬¡è¿è¡Œï¼ˆå•æ¬¡è°ƒç”¨ï¼‰æœ€å¤š 5 æ¬¡è°ƒç”¨
            exit_behavior="end",  # æˆ–è€… "error" ä»¥å¼•å‘å¼‚å¸¸
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `thread_limit`: **æ•°å­—**ï¼Œçº¿ç¨‹ä¸­æ‰€æœ‰è¿è¡Œçš„æœ€å¤§æ¨¡å‹è°ƒç”¨æ¬¡æ•°ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶ã€‚
*   `run_limit`: **æ•°å­—**ï¼Œå•æ¬¡è°ƒç”¨ä¸­æœ€å¤§æ¨¡å‹è°ƒç”¨æ¬¡æ•°ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶ã€‚
*   `exit_behavior`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "end")**ï¼Œè¾¾åˆ°é™åˆ¶æ—¶çš„è¡Œä¸ºã€‚é€‰é¡¹ï¼š`"end"`ï¼ˆä¼˜é›…ç»ˆæ­¢ï¼‰æˆ– `"error"`ï¼ˆå¼•å‘å¼‚å¸¸ï¼‰ã€‚

### é™åˆ¶å·¥å…·è°ƒç”¨ (Tool call limit)

é™åˆ¶ç‰¹å®šå·¥å…·æˆ–æ‰€æœ‰å·¥å…·çš„è°ƒç”¨æ¬¡æ•°ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   é˜²æ­¢å¯¹æ˜‚è´µçš„å¤–éƒ¨ API è¿›è¡Œ**è¿‡å¤šè°ƒç”¨**
> *   é™åˆ¶**ç½‘é¡µæœç´¢**æˆ–**æ•°æ®åº“æŸ¥è¯¢**
> *   å¯¹ç‰¹å®šå·¥å…·ä½¿ç”¨**å¼ºåˆ¶æ‰§è¡Œé€Ÿç‡é™åˆ¶**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ToolCallLimitMiddleware
# é™åˆ¶æ‰€æœ‰å·¥å…·è°ƒç”¨
global_limiter = ToolCallLimitMiddleware(thread_limit=20, run_limit=10)
# é™åˆ¶ç‰¹å®šå·¥å…·
search_limiter = ToolCallLimitMiddleware(
    tool_name="search",
    thread_limit=5,
    run_limit=3,
)
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[global_limiter, search_limiter],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `tool_name`: **å­—ç¬¦ä¸²**ï¼Œè¦é™åˆ¶çš„ç‰¹å®šå·¥å…·ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™é™åˆ¶é€‚ç”¨äºæ‰€æœ‰å·¥å…·ã€‚
*   `thread_limit`: **æ•°å­—**ï¼Œçº¿ç¨‹ä¸­æ‰€æœ‰è¿è¡Œçš„æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶ã€‚
*   `run_limit`: **æ•°å­—**ï¼Œå•æ¬¡è°ƒç”¨ä¸­æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶ã€‚
*   `exit_behavior`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "end")**ï¼Œè¾¾åˆ°é™åˆ¶æ—¶çš„è¡Œä¸ºã€‚é€‰é¡¹ï¼š`"end"`ï¼ˆä¼˜é›…ç»ˆæ­¢ï¼‰æˆ– `"error"`ï¼ˆå¼•å‘å¼‚å¸¸ï¼‰ã€‚

### æ¨¡å‹å›é€€ (Model fallback)

å½“ä¸»è¦æ¨¡å‹å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å›é€€åˆ°æ›¿ä»£æ¨¡å‹ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   æ„å»ºèƒ½å¤Ÿå¤„ç†**æ¨¡å‹ä¸­æ–­**çš„å¼¹æ€§ä»£ç†
> *   é€šè¿‡å›é€€åˆ°æ›´ä¾¿å®œçš„æ¨¡å‹å®ç°**æˆæœ¬ä¼˜åŒ–**
> *   è·¨ OpenAIã€Anthropic ç­‰æä¾›å•†å®ç°**å†—ä½™**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ModelFallbackMiddleware
agent = create_agent(
    model="openai:gpt-4o",  # ä¸»è¦æ¨¡å‹
    tools=[...],
    middleware=[
        ModelFallbackMiddleware(
            "openai:gpt-4o-mini",  # é”™è¯¯æ—¶é¦–å…ˆå°è¯•
            "anthropic:claude-3-5-sonnet-20241022",  # ç„¶åå°è¯•è¿™ä¸ª
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `first_model`: **å­—ç¬¦ä¸² | BaseChatModel (å¿…éœ€)**ï¼Œä¸»è¦æ¨¡å‹å¤±è´¥æ—¶å°è¯•çš„ç¬¬ä¸€ä¸ªå›é€€æ¨¡å‹ã€‚å¯ä»¥æ˜¯æ¨¡å‹å­—ç¬¦ä¸²ï¼ˆä¾‹å¦‚ï¼Œ`"openai:gpt-4o-mini"`ï¼‰æˆ– `BaseChatModel` å®ä¾‹ã€‚
*   `*additional_models`: **å­—ç¬¦ä¸² | BaseChatModel**ï¼Œå¦‚æœå…ˆå‰çš„æ¨¡å‹å¤±è´¥ï¼Œåˆ™æŒ‰é¡ºåºå°è¯•çš„å…¶ä»–å›é€€æ¨¡å‹ã€‚

### PII æ£€æµ‹ (PII detection)

æ£€æµ‹å’Œå¤„ç†å¯¹è¯ä¸­çš„**ä¸ªäººèº«ä»½ä¿¡æ¯**ï¼ˆPersonally Identifiable Information, PIIï¼‰ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   å…·æœ‰åˆè§„æ€§è¦æ±‚çš„**åŒ»ç–—ä¿å¥å’Œé‡‘èåº”ç”¨**
> *   éœ€è¦æ¸…ç†æ—¥å¿—çš„**å®¢æˆ·æœåŠ¡ä»£ç†**
> *   ä»»ä½•å¤„ç†**æ•æ„Ÿç”¨æˆ·æ•°æ®**çš„åº”ç”¨

```python
from langchain.agents import create_agent
from langchain.agents.middleware import PIIMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[
        # æ¶‚æ”¹ç”¨æˆ·è¾“å…¥ä¸­çš„ç”µå­é‚®ä»¶
        PIIMiddleware("email", strategy="redact", apply_to_input=True),
        # æ©ç›–ä¿¡ç”¨å¡ï¼ˆæ˜¾ç¤ºå 4 ä½ï¼‰
        PIIMiddleware("credit_card", strategy="mask", apply_to_input=True),
        # å¸¦æœ‰æ­£åˆ™è¡¨è¾¾å¼çš„è‡ªå®šä¹‰ PII ç±»å‹
        PIIMiddleware(
            "api_key",
            detector=r"sk-[a-zA-Z0-9]{32}",
            strategy="block",  # å¦‚æœæ£€æµ‹åˆ°ï¼Œåˆ™å¼•å‘é”™è¯¯
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `pii_type`: **å­—ç¬¦ä¸² (å¿…éœ€)**ï¼Œè¦æ£€æµ‹çš„ PII ç±»å‹ã€‚å¯ä»¥æ˜¯å†…ç½®ç±»å‹ï¼ˆ`email`ã€`credit_card`ã€`ip`ã€`mac_address`ã€`url`ï¼‰æˆ–è‡ªå®šä¹‰ç±»å‹åç§°ã€‚
*   `strategy`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "redact")**ï¼Œå¤„ç†æ£€æµ‹åˆ°çš„ PII çš„æ–¹å¼ã€‚é€‰é¡¹ï¼š
    *   `"block"` - æ£€æµ‹åˆ°æ—¶å¼•å‘å¼‚å¸¸
    *   `"redact"` - æ›¿æ¢ä¸º `[REDACTED_TYPE]`
    *   `"mask"` - éƒ¨åˆ†æ©ç›–ï¼ˆä¾‹å¦‚ï¼Œ`****-****-****-1234`ï¼‰
    *   `"hash"` - æ›¿æ¢ä¸ºç¡®å®šæ€§å“ˆå¸Œ
*   `detector`: **å‡½æ•° | æ­£åˆ™è¡¨è¾¾å¼**ï¼Œè‡ªå®šä¹‰æ£€æµ‹å‡½æ•°æˆ–æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ã€‚å¦‚æœæœªæä¾›ï¼Œåˆ™ä½¿ç”¨ PII ç±»å‹çš„å†…ç½®æ£€æµ‹å™¨ã€‚
*   `apply_to_input`: **å¸ƒå°”å€¼ (é»˜è®¤å€¼: True)**ï¼Œåœ¨æ¨¡å‹è°ƒç”¨å‰æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯ã€‚
*   `apply_to_output`: **å¸ƒå°”å€¼ (é»˜è®¤å€¼: False)**ï¼Œåœ¨æ¨¡å‹è°ƒç”¨åæ£€æŸ¥ AI æ¶ˆæ¯ã€‚
*   `apply_to_tool_results`: **å¸ƒå°”å€¼ (é»˜è®¤å€¼: False)**ï¼Œåœ¨æ‰§è¡Œåæ£€æŸ¥å·¥å…·ç»“æœæ¶ˆæ¯ã€‚

### è§„åˆ’ (Planning)

ä¸ºå¤æ‚çš„**å¤šæ­¥éª¤ä»»åŠ¡**æ·»åŠ å¾…åŠäº‹é¡¹åˆ—è¡¨ç®¡ç†åŠŸèƒ½ã€‚

> **æ³¨æ„ï¼š** æ­¤ä¸­é—´ä»¶è‡ªåŠ¨ä¸ºä»£ç†æä¾›ä¸€ä¸ª `write_todos` å·¥å…·å’Œç³»ç»Ÿæç¤ºè¯ï¼Œä»¥æŒ‡å¯¼æœ‰æ•ˆçš„ä»»åŠ¡è§„åˆ’ã€‚

```python
from langchain.agents import create_agent
from langchain.agents.middleware import TodoListMiddleware
from langchain.messages import HumanMessage
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[TodoListMiddleware()],
)
result = agent.invoke({"messages": [HumanMessage("Help me refactor my codebase")]})
print(result["todos"])  # å¸¦æœ‰çŠ¶æ€è·Ÿè¸ªçš„å¾…åŠäº‹é¡¹æ•°ç»„
```

**é…ç½®é€‰é¡¹ï¼š**

*   `system_prompt`: **å­—ç¬¦ä¸²**ï¼Œç”¨äºæŒ‡å¯¼å¾…åŠäº‹é¡¹ä½¿ç”¨çš„è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨å†…ç½®æç¤ºè¯ã€‚
*   `tool_description`: **å­—ç¬¦ä¸²**ï¼Œ`write_todos` å·¥å…·çš„è‡ªå®šä¹‰æè¿°ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨å†…ç½®æè¿°ã€‚

### LLM å·¥å…·é€‰æ‹©å™¨ (LLM tool selector)

åœ¨è°ƒç”¨ä¸»æ¨¡å‹ä¹‹å‰ï¼Œä½¿ç”¨ LLM æ™ºèƒ½åœ°é€‰æ‹©**ç›¸å…³å·¥å…·**ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   å…·æœ‰**è®¸å¤šå·¥å…·ï¼ˆ10+ï¼‰**ï¼Œä½†å¤§å¤šæ•°å·¥å…·ä¸æŸ¥è¯¢ä¸ç›¸å…³çš„ä»£ç†
> *   é€šè¿‡è¿‡æ»¤ä¸ç›¸å…³çš„å·¥å…·æ¥**å‡å°‘ token ä½¿ç”¨**
> *   **æé«˜æ¨¡å‹ç„¦ç‚¹**å’Œå‡†ç¡®æ€§

```python
from langchain.agents import create_agent
from langchain.agents.middleware import LLMToolSelectorMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[tool1, tool2, tool3, tool4, tool5, ...],  # è®¸å¤šå·¥å…·
    middleware=[
        LLMToolSelectorMiddleware(
            model="openai:gpt-4o-mini",  # ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹è¿›è¡Œé€‰æ‹©
            max_tools=3,  # é™åˆ¶ä¸º 3 ä¸ªæœ€ç›¸å…³çš„å·¥å…·
            always_include=["search"],  # å§‹ç»ˆåŒ…å«æŸäº›å·¥å…·
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `model`: **å­—ç¬¦ä¸² | BaseChatModel**ï¼Œç”¨äºå·¥å…·é€‰æ‹©çš„æ¨¡å‹ã€‚å¯ä»¥æ˜¯æ¨¡å‹å­—ç¬¦ä¸²æˆ– `BaseChatModel` å®ä¾‹ã€‚é»˜è®¤ä¸ºä»£ç†çš„ä¸»æ¨¡å‹ã€‚
*   `system_prompt`: **å­—ç¬¦ä¸²**ï¼Œç»™é€‰æ‹©æ¨¡å‹çš„æŒ‡ä»¤ã€‚å¦‚æœæœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨å†…ç½®æç¤ºè¯ã€‚
*   `max_tools`: **æ•°å­—**ï¼Œè¦é€‰æ‹©çš„æœ€å¤§å·¥å…·æ•°é‡ã€‚é»˜è®¤ä¸ºæ— é™åˆ¶ã€‚
*   `always_include`: **å­—ç¬¦ä¸²åˆ—è¡¨**ï¼Œå§‹ç»ˆåŒ…å«åœ¨é€‰æ‹©ä¸­çš„å·¥å…·åç§°åˆ—è¡¨ã€‚

### å·¥å…·é‡è¯• (Tool retry)

ä½¿ç”¨å¯é…ç½®çš„**æŒ‡æ•°å›é€€**è‡ªåŠ¨é‡è¯•å¤±è´¥çš„å·¥å…·è°ƒç”¨ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   å¤„ç†**å¤–éƒ¨ API è°ƒç”¨ä¸­çš„ç¬æ—¶æ•…éšœ**
> *   æé«˜**ä¾èµ–ç½‘ç»œçš„å·¥å…·**çš„å¯é æ€§
> *   æ„å»ºèƒ½å¤Ÿ**ä¼˜é›…å¤„ç†ä¸´æ—¶é”™è¯¯**çš„å¼¹æ€§ä»£ç†

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ToolRetryMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, database_tool],
    middleware=[
        ToolRetryMiddleware(
            max_retries=3,  # æœ€å¤šé‡è¯• 3 æ¬¡
            backoff_factor=2.0,  # æŒ‡æ•°å›é€€ä¹˜æ•°
            initial_delay=1.0,  # ä» 1 ç§’å»¶è¿Ÿå¼€å§‹
            max_delay=60.0,  # å°†å»¶è¿Ÿä¸Šé™è®¾ç½®ä¸º 60 ç§’
            jitter=True,  # æ·»åŠ éšæœºæŠ–åŠ¨ä»¥é¿å…â€œæƒŠç¾¤â€é—®é¢˜
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `max_retries`: **æ•°å­— (é»˜è®¤å€¼: 2)**ï¼Œåˆå§‹è°ƒç”¨åçš„æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤æ€»å…± 3 æ¬¡å°è¯•ï¼‰ã€‚
*   `tools`: **BaseTool | å­—ç¬¦ä¸²åˆ—è¡¨**ï¼Œå¯é€‰çš„å·¥å…·åˆ—è¡¨æˆ–å·¥å…·åç§°ï¼Œç”¨äºåº”ç”¨é‡è¯•é€»è¾‘ã€‚å¦‚æœä¸º `None`ï¼Œåˆ™åº”ç”¨äºæ‰€æœ‰å·¥å…·ã€‚
*   `retry_on`: **å¼‚å¸¸ç±»å‹å…ƒç»„ | å¯è°ƒç”¨å¯¹è±¡ (é»˜è®¤å€¼: (Exception,))**ï¼Œè¦ä¹ˆæ˜¯é‡è¯•çš„å¼‚å¸¸ç±»å‹å…ƒç»„ï¼Œè¦ä¹ˆæ˜¯æ¥å—å¼‚å¸¸å¹¶è¿”å› `True` è¡¨ç¤ºåº”é‡è¯•çš„å¯è°ƒç”¨å¯¹è±¡ã€‚
*   `on_failure`: **å­—ç¬¦ä¸² | å¯è°ƒç”¨å¯¹è±¡ (é»˜è®¤å€¼: "return_message")**ï¼Œæ‰€æœ‰é‡è¯•è€—å°½æ—¶çš„è¡Œä¸ºã€‚é€‰é¡¹ï¼š
    *   `"return_message"` - è¿”å›å¸¦æœ‰é”™è¯¯è¯¦ç»†ä¿¡æ¯çš„ ToolMessageï¼ˆå…è®¸ LLM å¤„ç†å¤±è´¥ï¼‰
    *   `"raise"` - é‡æ–°å¼•å‘å¼‚å¸¸ï¼ˆåœæ­¢ä»£ç†æ‰§è¡Œï¼‰
    *   è‡ªå®šä¹‰å¯è°ƒç”¨å¯¹è±¡ - æ¥å—å¼‚å¸¸å¹¶è¿”å›ç”¨äº ToolMessage å†…å®¹çš„å­—ç¬¦ä¸²çš„å‡½æ•°
*   `backoff_factor`: **æ•°å­— (é»˜è®¤å€¼: 2.0)**ï¼ŒæŒ‡æ•°å›é€€çš„ä¹˜æ•°ã€‚æ¯æ¬¡é‡è¯•ç­‰å¾… `initial_delay * (backoff_factor ** retry_number)` ç§’ã€‚è®¾ç½®ä¸º 0.0 è¡¨ç¤ºæ’å®šå»¶è¿Ÿã€‚
*   `initial_delay`: **æ•°å­— (é»˜è®¤å€¼: 1.0)**ï¼Œç¬¬ä¸€æ¬¡é‡è¯•å‰çš„åˆå§‹å»¶è¿Ÿï¼ˆç§’ï¼‰ã€‚
*   `max_delay`: **æ•°å­— (é»˜è®¤å€¼: 60.0)**ï¼Œé‡è¯•ä¹‹é—´çš„æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼ˆé™åˆ¶æŒ‡æ•°å›é€€çš„å¢é•¿ï¼‰ã€‚
*   `jitter`: **å¸ƒå°”å€¼ (é»˜è®¤å€¼: true)**ï¼Œæ˜¯å¦æ·»åŠ éšæœºæŠ–åŠ¨ï¼ˆÂ±25%ï¼‰ä»¥é¿å…â€œæƒŠç¾¤â€é—®é¢˜ã€‚

### LLM å·¥å…·æ¨¡æ‹Ÿå™¨ (LLM tool emulator)

ä½¿ç”¨ LLM æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œï¼Œç”¨äºæµ‹è¯•ç›®çš„ï¼Œç”¨ AI ç”Ÿæˆçš„å“åº”**æ›¿æ¢å®é™…å·¥å…·è°ƒç”¨**ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   **åœ¨ä¸æ‰§è¡ŒçœŸå®å·¥å…·çš„æƒ…å†µä¸‹æµ‹è¯•ä»£ç†è¡Œä¸º**
> *   åœ¨**å¤–éƒ¨å·¥å…·ä¸å¯ç”¨æˆ–æ˜‚è´µ**æ—¶å¼€å‘ä»£ç†
> *   åœ¨å®ç°å®é™…å·¥å…·ä¹‹å‰**è¿›è¡Œä»£ç†å·¥ä½œæµåŸå‹è®¾è®¡**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import LLMToolEmulator
agent = create_agent(
    model="openai:gpt-4o",
    tools=[get_weather, search_database, send_email],
    middleware=[
        # é»˜è®¤æ¨¡æ‹Ÿæ‰€æœ‰å·¥å…·
        LLMToolEmulator(),
        # æˆ–æ¨¡æ‹Ÿç‰¹å®šå·¥å…·
        # LLMToolEmulator(tools=["get_weather", "search_database"]),
        # æˆ–ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹è¿›è¡Œæ¨¡æ‹Ÿ
        # LLMToolEmulator(model="anthropic:claude-3-5-sonnet-latest"),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `tools`: **å­—ç¬¦ä¸² | BaseTool åˆ—è¡¨**ï¼Œè¦æ¨¡æ‹Ÿçš„å·¥å…·åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ– `BaseTool` å®ä¾‹åˆ—è¡¨ã€‚å¦‚æœä¸º `None`ï¼ˆé»˜è®¤ï¼‰ï¼Œ**æ‰€æœ‰**å·¥å…·å°†è¢«æ¨¡æ‹Ÿã€‚å¦‚æœä¸ºç©ºåˆ—è¡¨ï¼Œåˆ™ä¸ä¼šæ¨¡æ‹Ÿä»»ä½•å·¥å…·ã€‚
*   `model`: **å­—ç¬¦ä¸² | BaseChatModel (é»˜è®¤å€¼: "anthropic:claude-3-5-sonnet-latest")**ï¼Œç”¨äºç”Ÿæˆæ¨¡æ‹Ÿå·¥å…·å“åº”çš„æ¨¡å‹ã€‚å¯ä»¥æ˜¯æ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²æˆ– `BaseChatModel` å®ä¾‹ã€‚

### ä¸Šä¸‹æ–‡ç¼–è¾‘ (Context editing)

é€šè¿‡**ä¿®å‰ª**ã€**æ‘˜è¦**æˆ–**æ¸…é™¤å·¥å…·ä½¿ç”¨**æ¥ç®¡ç†å¯¹è¯ä¸Šä¸‹æ–‡ã€‚

> **å®Œç¾é€‚ç”¨äºï¼š**
> *   éœ€è¦å®šæœŸ**æ¸…ç†ä¸Šä¸‹æ–‡**çš„é•¿æ—¶é—´å¯¹è¯
> *   ä»ä¸Šä¸‹æ–‡ä¸­**ç§»é™¤å¤±è´¥çš„å·¥å…·å°è¯•**
> *   **è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥**

```python
from langchain.agents import create_agent
from langchain.agents.middleware import ContextEditingMiddleware, ClearToolUsesEdit
agent = create_agent(
    model="openai:gpt-4o",
    tools=[...],
    middleware=[
        ContextEditingMiddleware(
            edits=[
                ClearToolUsesEdit(max_tokens=1000),  # æ¸…é™¤æ—§çš„å·¥å…·ä½¿ç”¨
            ],
        ),
    ],
)
```

**é…ç½®é€‰é¡¹ï¼š**

*   `edits`: **ContextEdit åˆ—è¡¨ (é»˜è®¤å€¼: [ClearToolUsesEdit()])**ï¼Œè¦åº”ç”¨çš„ `ContextEdit` ç­–ç•¥åˆ—è¡¨ã€‚
*   `token_count_method`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "approximate")**ï¼Œtoken è®¡æ•°æ–¹æ³•ã€‚é€‰é¡¹ï¼š`"approximate"` æˆ– `"model"`ã€‚

**`ClearToolUsesEdit` é€‰é¡¹ï¼š**

*   `trigger`: **æ•°å­— (é»˜è®¤å€¼: 100000)**ï¼Œè§¦å‘ç¼–è¾‘çš„ token è®¡æ•°ã€‚
*   `clear_at_least`: **æ•°å­— (é»˜è®¤å€¼: 0)**ï¼Œè¦å›æ”¶çš„æœ€å° token æ•°ã€‚
*   `keep`: **æ•°å­— (é»˜è®¤å€¼: 3)**ï¼Œè¦ä¿ç•™çš„æœ€è¿‘å·¥å…·ç»“æœæ•°é‡ã€‚
*   `clear_tool_inputs`: **å¸ƒå°”å€¼ (é»˜è®¤å€¼: False)**ï¼Œæ˜¯å¦æ¸…é™¤å·¥å…·è°ƒç”¨å‚æ•°ã€‚
*   `exclude_tools`: **å­—ç¬¦ä¸²åˆ—è¡¨ (é»˜è®¤å€¼: ())**ï¼Œè¦ä»æ¸…é™¤ä¸­æ’é™¤çš„å·¥å…·åç§°åˆ—è¡¨ã€‚
*   `placeholder`: **å­—ç¬¦ä¸² (é»˜è®¤å€¼: "[cleared]")**ï¼Œæ¸…é™¤è¾“å‡ºçš„å ä½ç¬¦æ–‡æœ¬ã€‚

## è‡ªå®šä¹‰ä¸­é—´ä»¶ (Custom middleware)

é€šè¿‡å®ç°è¿è¡Œåœ¨ä»£ç†æ‰§è¡Œæµç¨‹ä¸­ç‰¹å®šç‚¹çš„**é’©å­**ï¼ˆhooksï¼‰æ¥æ„å»ºè‡ªå®šä¹‰ä¸­é—´ä»¶ã€‚

æ‚¨å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼åˆ›å»ºä¸­é—´ä»¶ï¼š

1.  **åŸºäºè£…é¥°å™¨ (Decorator-based)** - é€‚ç”¨äºå•é’©å­ä¸­é—´ä»¶ï¼Œå¿«é€Ÿä¸”ç®€å•
2.  **åŸºäºç±» (Class-based)** - é€‚ç”¨äºå…·æœ‰å¤šä¸ªé’©å­çš„å¤æ‚ä¸­é—´ä»¶ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§

### åŸºäºè£…é¥°å™¨çš„ä¸­é—´ä»¶

å¯¹äºåªéœ€è¦ä¸€ä¸ªé’©å­çš„ç®€å•ä¸­é—´ä»¶ï¼Œè£…é¥°å™¨æä¾›äº†æœ€å¿«çš„æ–¹æ³•æ¥æ·»åŠ åŠŸèƒ½ï¼š

```python
from langchain.agents.middleware import before_model, after_model, wrap_model_call
from langchain.agents.middleware import AgentState, ModelRequest, ModelResponse, dynamic_prompt
from langchain.messages import AIMessage
from langchain.agents import create_agent
from langgraph.runtime import Runtime
from typing import Any, Callable
# èŠ‚ç‚¹å¼ (Node-style)ï¼šæ¨¡å‹è°ƒç”¨å‰çš„æ—¥å¿—è®°å½•
@before_model
def log_before_model(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    print(f"About to call model with {len(state['messages'])} messages")
    return None
# èŠ‚ç‚¹å¼ (Node-style)ï¼šæ¨¡å‹è°ƒç”¨åçš„éªŒè¯
@after_model(can_jump_to=["end"])
def validate_output(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    last_message = state["messages"][-1]
    if "BLOCKED" in last_message.content:
        return {
            "messages": [AIMessage("I cannot respond to that request.")],
            "jump_to": "end"
        }
    return None
# åŒ…è£…å¼ (Wrap-style)ï¼šé‡è¯•é€»è¾‘
@wrap_model_call
def retry_model(
    request: ModelRequest,
    handler: Callable[[ModelRequest], ModelResponse],
) -> ModelResponse:
    for attempt in range(3):
        try:
            return handler(request)
        except Exception as e:
            if attempt == 2:
                raise
            print(f"Retry {attempt + 1}/3 after error: {e}")
# åŒ…è£…å¼ (Wrap-style)ï¼šåŠ¨æ€æç¤ºè¯
@dynamic_prompt
def personalized_prompt(request: ModelRequest) -> str:
    user_id = request.runtime.context.get("user_id", "guest")
    return f"You are a helpful assistant for user {user_id}. Be concise and friendly."
# åœ¨ä»£ç†ä¸­ä½¿ç”¨è£…é¥°å™¨
agent = create_agent(
    model="openai:gpt-4o",
    middleware=[log_before_model, validate_output, retry_model, personalized_prompt],
    tools=[...],
)
```

#### å¯ç”¨è£…é¥°å™¨

**èŠ‚ç‚¹å¼ (Node-style)**ï¼ˆåœ¨ç‰¹å®šçš„æ‰§è¡Œç‚¹è¿è¡Œï¼‰ï¼š

*   `@before_agent` - ä»£ç†å¯åŠ¨å‰ï¼ˆæ¯æ¬¡è°ƒç”¨ä¸€æ¬¡ï¼‰
*   `@before_model` - æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‰
*   `@after_model` - æ¯æ¬¡æ¨¡å‹å“åº”å
*   `@after_agent` - ä»£ç†å®Œæˆæ—¶ï¼ˆæ¯æ¬¡è°ƒç”¨æœ€å¤šä¸€æ¬¡ï¼‰

**åŒ…è£…å¼ (Wrap-style)**ï¼ˆæ‹¦æˆªå¹¶æ§åˆ¶æ‰§è¡Œï¼‰ï¼š

*   `@wrap_model_call` - æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‘¨å›´
*   `@wrap_tool_call` - æ¯æ¬¡å·¥å…·è°ƒç”¨å‘¨å›´

**ä¾¿åˆ©è£…é¥°å™¨ (Convenience decorators)**ï¼š

*   `@dynamic_prompt` - ç”ŸæˆåŠ¨æ€ç³»ç»Ÿæç¤ºè¯ï¼ˆç›¸å½“äºä¿®æ”¹æç¤ºè¯çš„ `@wrap_model_call`ï¼‰

#### ä½•æ—¶ä½¿ç”¨è£…é¥°å™¨

| âœ”ï¸ ä½¿ç”¨è£…é¥°å™¨çš„æ—¶æœº | ğŸ’» ä½¿ç”¨ç±»çš„æ—¶æœº |
| :--- | :--- |
| â€¢ æ‚¨åªéœ€è¦ä¸€ä¸ªé’©å­ | â€¢ éœ€è¦å¤šä¸ªé’©å­ |
| â€¢ æ²¡æœ‰å¤æ‚çš„é…ç½® | â€¢ å¤æ‚çš„é…ç½® |
| | â€¢ è·¨é¡¹ç›®å¤ç”¨ï¼ˆé€šè¿‡åˆå§‹åŒ–é…ç½®ï¼‰ |

### åŸºäºç±»çš„ä¸­é—´ä»¶

#### ä¸¤ç§é’©å­æ ·å¼

*   **é¡¹ç›®å›¾è¡¨ èŠ‚ç‚¹å¼é’©å­ (Node-style hooks)**
    åœ¨ç‰¹å®šçš„æ‰§è¡Œç‚¹**é¡ºåºè¿è¡Œ**ã€‚ç”¨äºæ—¥å¿—è®°å½•ã€éªŒè¯å’ŒçŠ¶æ€æ›´æ–°ã€‚

*   **åŒ…è£…å¼é’©å­ (Wrap-style hooks)**
    **æ‹¦æˆªæ‰§è¡Œ**å¹¶å¯¹å¤„ç†ç¨‹åºè°ƒç”¨å…·æœ‰å®Œå…¨æ§åˆ¶ã€‚ç”¨äºé‡è¯•ã€ç¼“å­˜å’Œè½¬æ¢ã€‚

#### èŠ‚ç‚¹å¼é’©å­ (Node-style hooks)

åœ¨æ‰§è¡Œæµç¨‹ä¸­çš„ç‰¹å®šç‚¹è¿è¡Œï¼š

*   `before_agent` - ä»£ç†å¯åŠ¨å‰ï¼ˆæ¯æ¬¡è°ƒç”¨ä¸€æ¬¡ï¼‰
*   `before_model` - æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‰
*   `after_model` - æ¯æ¬¡æ¨¡å‹å“åº”å
*   `after_agent` - ä»£ç†å®Œæˆæ—¶ï¼ˆæ¯æ¬¡è°ƒç”¨æœ€å¤šä¸€æ¬¡ï¼‰

**ç¤ºä¾‹ï¼šæ—¥å¿—è®°å½•ä¸­é—´ä»¶**

```python
from langchain.agents.middleware import AgentMiddleware, AgentState
from langgraph.runtime import Runtime
from typing import Any
class LoggingMiddleware(AgentMiddleware):
    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        print(f"About to call model with {len(state['messages'])} messages")
        return None
    def after_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        print(f"Model returned: {state['messages'][-1].content}")
        return None
```

**ç¤ºä¾‹ï¼šå¯¹è¯é•¿åº¦é™åˆ¶**

```python
from langchain.agents.middleware import AgentMiddleware, AgentState
from langchain.messages import AIMessage
from langgraph.runtime import Runtime
from typing import Any
class MessageLimitMiddleware(AgentMiddleware):
    def __init__(self, max_messages: int = 50):
        super().__init__()
        self.max_messages = max_messages
    def before_model(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        if len(state["messages"]) == self.max_messages:
            return {
                "messages": [AIMessage("Conversation limit reached.")],
                "jump_to": "end"
            }
        return None
```

#### åŒ…è£…å¼é’©å­ (Wrap-style hooks)

æ‹¦æˆªæ‰§è¡Œå¹¶æ§åˆ¶ä½•æ—¶è°ƒç”¨å¤„ç†ç¨‹åºï¼š

*   `wrap_model_call` - æ¯æ¬¡æ¨¡å‹è°ƒç”¨å‘¨å›´
*   `wrap_tool_call` - æ¯æ¬¡å·¥å…·è°ƒç”¨å‘¨å›´

æ‚¨å¯ä»¥å†³å®šå¤„ç†ç¨‹åºæ˜¯è°ƒç”¨**é›¶æ¬¡**ï¼ˆçŸ­è·¯ï¼‰ã€**ä¸€æ¬¡**ï¼ˆæ­£å¸¸æµç¨‹ï¼‰è¿˜æ˜¯**å¤šæ¬¡**ï¼ˆé‡è¯•é€»è¾‘ï¼‰ã€‚

**ç¤ºä¾‹ï¼šæ¨¡å‹é‡è¯•ä¸­é—´ä»¶**

```python
from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse
from typing import Callable
class RetryMiddleware(AgentMiddleware):
    def __init__(self, max_retries: int = 3):
        super().__init__()
        self.max_retries = max_retries
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        for attempt in range(self.max_retries):
            try:
                return handler(request)
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise
                print(f"Retry {attempt + 1}/{self.max_retries} after error: {e}")
```

**ç¤ºä¾‹ï¼šåŠ¨æ€æ¨¡å‹é€‰æ‹©**

```python
from langchain.agents.middleware import AgentMiddleware, ModelRequest, ModelResponse
from langchain.chat_models import init_chat_model
from typing import Callable
class DynamicModelMiddleware(AgentMiddleware):
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse],
    ) -> ModelResponse:
        # æ ¹æ®å¯¹è¯é•¿åº¦ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
        # ...