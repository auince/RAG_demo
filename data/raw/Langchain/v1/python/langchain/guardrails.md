# å®ˆå«

> ä¸ºæ‚¨çš„æ™ºèƒ½ä½“å®æ–½å®‰å…¨æ£€æŸ¥å’Œå†…å®¹è¿‡æ»¤

å®ˆå«é€šè¿‡åœ¨æ‚¨çš„æ™ºèƒ½ä½“æ‰§è¡Œçš„å…³é”®ç‚¹éªŒè¯å’Œè¿‡æ»¤å†…å®¹ï¼Œå¸®åŠ©æ‚¨æ„å»º**å®‰å…¨ã€åˆè§„**çš„ AI åº”ç”¨ã€‚å®ƒä»¬å¯ä»¥åœ¨é—®é¢˜å‘ç”Ÿå‰æ£€æµ‹æ•æ„Ÿä¿¡æ¯ã€å¼ºåˆ¶æ‰§è¡Œå†…å®¹ç­–ç•¥ã€éªŒè¯è¾“å‡ºå¹¶é˜²æ­¢ä¸å®‰å…¨è¡Œä¸ºã€‚

### å¸¸è§ç”¨ä¾‹

*   **é˜²æ­¢ PIIï¼ˆä¸ªäººèº«ä»½ä¿¡æ¯ï¼‰æ³„éœ²**
*   **æ£€æµ‹å’Œé˜»æ­¢æç¤ºæ³¨å…¥ (prompt injection) æ”»å‡»**
*   **é˜»æ­¢ä¸å½“æˆ–æœ‰å®³å†…å®¹**
*   **å¼ºåˆ¶æ‰§è¡Œä¸šåŠ¡è§„åˆ™å’Œåˆè§„è¦æ±‚**
*   **éªŒè¯è¾“å‡ºè´¨é‡å’Œå‡†ç¡®æ€§**

æ‚¨å¯ä»¥ä½¿ç”¨ **[ä¸­é—´ä»¶ (middleware)](middleware.html)** æ¥å®æ–½å®ˆå«ï¼Œåœ¨ç­–ç•¥æ€§èŠ‚ç‚¹æ‹¦æˆªæ‰§è¡Œâ€”â€”åœ¨æ™ºèƒ½ä½“å¼€å§‹å‰ã€å®Œæˆåï¼Œæˆ–å›´ç»•æ¨¡å‹å’Œå·¥å…·è°ƒç”¨æ—¶ã€‚

### å®ˆå«çš„ä¸¤ç§æ–¹æ³•

å®ˆå«å¯ä»¥é€šè¿‡ä¸¤ç§äº’è¡¥çš„æ–¹æ³•å®æ–½ï¼š

| æ–¹æ³• | æè¿° |
| :--- | :--- |
| **ç¡®å®šæ€§å®ˆå« (Deterministic guardrails)** | ä½¿ç”¨åŸºäºè§„åˆ™çš„é€»è¾‘ï¼Œå¦‚æ­£åˆ™è¡¨è¾¾å¼ã€å…³é”®è¯åŒ¹é…æˆ–æ˜ç¡®æ£€æŸ¥ã€‚**å¿«é€Ÿã€å¯é¢„æµ‹ã€ç»æµé«˜æ•ˆ**ï¼Œä½†å¯èƒ½ä¼šé”™è¿‡ç»†å¾®çš„è¿è§„è¡Œä¸ºã€‚ |
| **åŸºäºæ¨¡å‹çš„å®ˆå« (Model-based guardrails)** | ä½¿ç”¨ **LLMs æˆ–åˆ†ç±»å™¨**é€šè¿‡è¯­ä¹‰ç†è§£æ¥è¯„ä¼°å†…å®¹ã€‚å¯ä»¥æ•è·è§„åˆ™é—æ¼çš„**å¾®å¦™é—®é¢˜**ï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ä¸”æˆæœ¬è¾ƒé«˜ã€‚ |

LangChain æä¾›äº†**å†…ç½®å®ˆå«**ï¼ˆä¾‹å¦‚ï¼Œ[PII æ£€æµ‹](#pii-detection)ã€[äººå·¥å®¡æ ¸](#human-in-the-loop)ï¼‰å’Œä¸€ä¸ªçµæ´»çš„ä¸­é—´ä»¶ç³»ç»Ÿï¼Œå¯ä½¿ç”¨ä»»ä¸€æ–¹æ³•æ„å»º**è‡ªå®šä¹‰å®ˆå«**ã€‚

## å†…ç½®å®ˆå« (Built-in guardrails)

### ä¸ªäººèº«ä»½ä¿¡æ¯ (PII) æ£€æµ‹

LangChain æä¾›äº†å†…ç½®ä¸­é—´ä»¶ç”¨äºæ£€æµ‹å’Œå¤„ç†å¯¹è¯ä¸­çš„**ä¸ªäººèº«ä»½ä¿¡æ¯ (PII)**ã€‚æ­¤ä¸­é—´ä»¶å¯ä»¥æ£€æµ‹å¸¸è§çš„ PII ç±»å‹ï¼Œå¦‚ç”µå­é‚®ä»¶ã€ä¿¡ç”¨å¡ã€IP åœ°å€ç­‰ã€‚

PII æ£€æµ‹ä¸­é—´ä»¶é€‚ç”¨äºéœ€è¦åˆè§„è¦æ±‚çš„åŒ»ç–—ä¿å¥å’Œé‡‘èåº”ç”¨ã€éœ€è¦æ¸…ç†æ—¥å¿—çš„å®¢æˆ·æœåŠ¡æ™ºèƒ½ä½“ï¼Œä»¥åŠé€šå¸¸å¤„ç†æ•æ„Ÿç”¨æˆ·æ•°æ®çš„ä»»ä½•åº”ç”¨ã€‚

PII ä¸­é—´ä»¶æ”¯æŒå¤šç§å¤„ç†æ£€æµ‹åˆ°çš„ PII çš„ç­–ç•¥ï¼š

| ç­–ç•¥ (`Strategy`) | æè¿° | ç¤ºä¾‹ |
| :--- | :--- | :--- |
| `redact` | æ›¿æ¢ä¸º `[REDACTED_TYPE]` | `[REDACTED_EMAIL]` |
| `mask` | éƒ¨åˆ†é®ç›–ï¼ˆä¾‹å¦‚ï¼Œå 4 ä½ï¼‰ | `****-****-****-1234` |
| `hash` | æ›¿æ¢ä¸ºç¡®å®šæ€§å“ˆå¸Œå€¼ | `a8f5f167...` |
| `block` | æ£€æµ‹åˆ°æ—¶æŠ›å‡ºå¼‚å¸¸ | æŠ›å‡ºé”™è¯¯ |

```python
from langchain.agents import create_agent
from langchain.agents.middleware import PIIMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[customer_service_tool, email_tool],
    middleware=[
        # åœ¨å‘é€ç»™æ¨¡å‹ä¹‹å‰ï¼Œå°†ç”¨æˆ·è¾“å…¥ä¸­çš„ç”µå­é‚®ä»¶ç¼–è¾‘æ‰
        PIIMiddleware(
            "email",
            strategy="redact",
            apply_to_input=True,
        ),
        # é®ç›–ç”¨æˆ·è¾“å…¥ä¸­çš„ä¿¡ç”¨å¡
        PIIMiddleware(
            "credit_card",
            strategy="mask",
            apply_to_input=True,
        ),
        # é˜»æ­¢ API å¯†é’¥ - å¦‚æœæ£€æµ‹åˆ°åˆ™æŠ›å‡ºé”™è¯¯
        PIIMiddleware(
            "api_key",
            detector=r"sk-[a-zA-Z0-9]{32}",
            strategy="block",
            apply_to_input=True,
        ),
    ],
)
# å½“ç”¨æˆ·æä¾› PII æ—¶ï¼Œå®ƒå°†æ ¹æ®ç­–ç•¥è¿›è¡Œå¤„ç†
result = agent.invoke({
    "messages": [{"role": "user", "content": "My email is john.doe@example.com and card is 4532-1234-5678-9010"}]
})
```

<details>
<summary>**å†…ç½® PII ç±»å‹å’Œé…ç½®**</summary>

**å†…ç½® PII ç±»å‹ï¼š**

*   `email` - ç”µå­é‚®ä»¶åœ°å€
*   `credit_card` - ä¿¡ç”¨å¡å·ï¼ˆç»è¿‡ Luhn éªŒè¯ï¼‰
*   `ip` - IP åœ°å€
*   `mac_address` - MAC åœ°å€
*   `url` - URL

**é…ç½®é€‰é¡¹ï¼š**

| å‚æ•° (`Parameter`) | æè¿° | é»˜è®¤å€¼ (`Default`) |
| :--- | :--- | :--- |
| `pii_type` | è¦æ£€æµ‹çš„ PII ç±»å‹ï¼ˆå†…ç½®æˆ–è‡ªå®šä¹‰ï¼‰ | å¿…éœ€ |
| `strategy` | å¦‚ä½•å¤„ç†æ£€æµ‹åˆ°çš„ PII (`"block"`, `"redact"`, `"mask"`, `"hash"`) | `"redact"` |
| `detector` | è‡ªå®šä¹‰æ£€æµ‹å™¨å‡½æ•°æˆ–æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ | `None`ï¼ˆä½¿ç”¨å†…ç½®ï¼‰ |
| `apply_to_input` | åœ¨æ¨¡å‹è°ƒç”¨å‰æ£€æŸ¥ç”¨æˆ·æ¶ˆæ¯ | `True` |
| `apply_to_output` | åœ¨æ¨¡å‹è°ƒç”¨åæ£€æŸ¥ AI æ¶ˆæ¯ | `False` |
| `apply_to_tool_results` | åœ¨æ‰§è¡Œåæ£€æŸ¥å·¥å…·ç»“æœæ¶ˆæ¯ | `False` |

</details>

è¯·å‚é˜… **[ä¸­é—´ä»¶æ–‡æ¡£](middleware.html#pii-detection)** äº†è§£ PII æ£€æµ‹åŠŸèƒ½çš„å®Œæ•´è¯¦æƒ…ã€‚

### äººå·¥å®¡æ ¸ (Human-in-the-loop)

LangChain æä¾›äº†å†…ç½®ä¸­é—´ä»¶ï¼Œè¦æ±‚åœ¨æ‰§è¡Œæ•æ„Ÿæ“ä½œä¹‹å‰è¿›è¡Œ**äººå·¥æ‰¹å‡†**ã€‚è¿™æ˜¯é’ˆå¯¹é«˜é£é™©å†³ç­–æœ€æœ‰æ•ˆçš„å®ˆå«ä¹‹ä¸€ã€‚

äººå·¥å®¡æ ¸ä¸­é—´ä»¶é€‚ç”¨äºä»¥ä¸‹æƒ…å†µï¼šé‡‘èäº¤æ˜“å’Œè½¬è´¦ã€åˆ é™¤æˆ–ä¿®æ”¹ç”Ÿäº§æ•°æ®ã€å‘å¤–éƒ¨æ–¹å‘é€é€šä¿¡ï¼Œä»¥åŠä»»ä½•å…·æœ‰é‡å¤§ä¸šåŠ¡å½±å“çš„æ“ä½œã€‚

```python
from langchain.agents import create_agent
from langchain.agents.middleware import HumanInTheLoopMiddleware
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, send_email_tool, delete_database_tool],
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                # è¦æ±‚æ‰¹å‡†æ•æ„Ÿæ“ä½œ
                "send_email": True,
                "delete_database": True,
                # è‡ªåŠ¨æ‰¹å‡†å®‰å…¨æ“ä½œ
                "search": False,
            }
        ),
    ],
    # åœ¨ä¸­æ–­æœŸé—´æŒä¹…åŒ–çŠ¶æ€
    checkpointer=InMemorySaver(),
)
# äººå·¥å®¡æ ¸éœ€è¦ä¸€ä¸ªçº¿ç¨‹ ID æ¥è¿›è¡ŒæŒä¹…åŒ–
config = {"configurable": {"thread_id": "some_id"}}
# åœ¨æ‰§è¡Œæ•æ„Ÿå·¥å…·ä¹‹å‰ï¼Œæ™ºèƒ½ä½“å°†æš‚åœå¹¶ç­‰å¾…æ‰¹å‡†
result = agent.invoke(
    {"messages": [{"role": "user", "content": "Send an email to the team"}]},
    config=config
)
result = agent.invoke(
    Command(resume={"decisions": [{"type": "approve"}]}),
    config=config # ç›¸åŒçš„çº¿ç¨‹ ID ä»¥æ¢å¤æš‚åœçš„å¯¹è¯
)
```

> ğŸ’¡ **æç¤ºï¼š**
> è¯·å‚é˜… **[äººå·¥å®¡æ ¸æ–‡æ¡£](human-in-the-loop.html)** äº†è§£å®æ–½æ‰¹å‡†å·¥ä½œæµç¨‹çš„å®Œæ•´è¯¦æƒ…ã€‚

## è‡ªå®šä¹‰å®ˆå« (Custom guardrails)

å¯¹äºæ›´å¤æ‚çš„å®ˆå«ï¼Œæ‚¨å¯ä»¥åˆ›å»º**è‡ªå®šä¹‰ä¸­é—´ä»¶**ï¼Œåœ¨æ™ºèƒ½ä½“æ‰§è¡Œä¹‹å‰æˆ–ä¹‹åè¿è¡Œã€‚è¿™ä½¿æ‚¨å¯ä»¥å®Œå…¨æ§åˆ¶éªŒè¯é€»è¾‘ã€å†…å®¹è¿‡æ»¤å’Œå®‰å…¨æ£€æŸ¥ã€‚

### æ™ºèƒ½ä½“æ‰§è¡Œå‰å®ˆå« (Before agent guardrails)

ä½¿ç”¨â€œ**æ™ºèƒ½ä½“æ‰§è¡Œå‰**â€çš„é’©å­ (hooks) åœ¨æ¯æ¬¡è°ƒç”¨å¼€å§‹æ—¶éªŒè¯è¯·æ±‚ä¸€æ¬¡ã€‚è¿™å¯¹äºä¼šè¯çº§åˆ«çš„æ£€æŸ¥ï¼ˆå¦‚èº«ä»½éªŒè¯ã€é€Ÿç‡é™åˆ¶æˆ–åœ¨ä»»ä½•å¤„ç†å¼€å§‹å‰é˜»æ­¢ä¸å½“è¯·æ±‚ï¼‰éå¸¸æœ‰ç”¨ã€‚

<details>
<summary> **ç±»çš„è¯­æ³•** </summary>

```python
from typing import Any
from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config
from langgraph.runtime import Runtime
class ContentFilterMiddleware(AgentMiddleware):
    """Deterministic guardrail: Block requests containing banned keywords."""
    def __init__(self, banned_keywords: list[str]):
        super().__init__()
        self.banned_keywords = [kw.lower() for kw in banned_keywords]
    @hook_config(can_jump_to=["end"])
    def before_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        # Get the first user message
        if not state["messages"]:
            return None
        first_message = state["messages"][0]
        if first_message.type != "human":
            return None
        content = first_message.content.lower()
        # Check for banned keywords
        for keyword in self.banned_keywords:
            if keyword in content:
                # Block execution before any processing
                return {
                    "messages": [{
                        "role": "assistant",
                        "content": "I cannot process requests containing inappropriate content. Please rephrase your request."
                    }],
                    "jump_to": "end"
                }
        return None
# Use the custom guardrail
from langchain.agents import create_agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, calculator_tool],
    middleware=[
        ContentFilterMiddleware(
            banned_keywords=["hack", "exploit", "malware"]
        ),
    ],
)
# This request will be blocked before any processing
result = agent.invoke({
    "messages": [{"role": "user", "content": "How do I hack into a database?"}]
})
```

</details>

<details>
<summary> **ä¿®é¥°ç¬¦çš„è¯­æ³•** </summary>

```python
from typing import Any
from langchain.agents.middleware import before_agent, AgentState, hook_config
from langgraph.runtime import Runtime
banned_keywords = ["hack", "exploit", "malware"]
@before_agent(can_jump_to=["end"])
def content_filter(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Deterministic guardrail: Block requests containing banned keywords."""
    # Get the first user message
    if not state["messages"]:
        return None
    first_message = state["messages"][0]
    if first_message.type != "human":
        return None
    content = first_message.content.lower()
    # Check for banned keywords
    for keyword in banned_keywords:
        if keyword in content:
            # Block execution before any processing
            return {
                "messages": [{
                    "role": "assistant",
                    "content": "I cannot process requests containing inappropriate content. Please rephrase your request."
                }],
                "jump_to": "end"
            }
    return None
# Use the custom guardrail
from langchain.agents import create_agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, calculator_tool],
    middleware=[content_filter],
)
# This request will be blocked before any processing
result = agent.invoke({
    "messages": [{"role": "user", "content": "How do I hack into a database?"}]
})
```

</details>

### æ™ºèƒ½ä½“æ‰§è¡Œåå®ˆå« (After agent guardrails)

ä½¿ç”¨â€œ**æ™ºèƒ½ä½“æ‰§è¡Œå**â€çš„é’©å­åœ¨è¿”å›ç»™ç”¨æˆ·ä¹‹å‰éªŒè¯æœ€ç»ˆè¾“å‡ºä¸€æ¬¡ã€‚è¿™å¯¹äºåŸºäºæ¨¡å‹çš„å®‰å…¨æ£€æŸ¥ã€è´¨é‡éªŒè¯æˆ–å¯¹å®Œæ•´çš„æ™ºèƒ½ä½“å“åº”è¿›è¡Œæœ€ç»ˆåˆè§„æ‰«æéå¸¸æœ‰ç”¨ã€‚

<details>
<summary>**ç±»çš„è¯­æ³•**</summary>

```python
from langchain.agents.middleware import AgentMiddleware, AgentState, hook_config
from langgraph.runtime import Runtime
from langchain_core.messages import AIMessage
from langchain.chat_models import init_chat_model
from typing import Any
class SafetyGuardrailMiddleware(AgentMiddleware):
    """Model-based guardrail: Use an LLM to evaluate response safety."""
    def __init__(self):
        super().__init__()
        self.safety_model = init_chat_model("openai:gpt-4o-mini")
    @hook_config(can_jump_to=["end"])
    def after_agent(self, state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
        # Get the final AI response
        if not state["messages"]:
            return None
        last_message = state["messages"][-1]
        if not isinstance(last_message, AIMessage):
            return None
        # Use a model to evaluate safety
        safety_prompt = f"""Evaluate if this response is safe and appropriate.
        Respond with only 'SAFE' or 'UNSAFE'.
        Response: {last_message.content}"""
        result = self.safety_model.invoke([{"role": "user", "content": safety_prompt}])
        if "UNSAFE" in result.content:
            return {
                "messages": [{
                    "role": "assistant",
                    "content": "I cannot provide that response. Please rephrase your request."
                }],
                "jump_to": "end"
            }
        return None
# Use the safety guardrail
from langchain.agents import create_agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, calculator_tool],
    middleware=[SafetyGuardrailMiddleware()],
)
result = agent.invoke({
    "messages": [{"role": "user", "content": "How do I make explosives?"}]
})
```

</details>

<details>
<summary>**ä¿®é¥°è¯çš„è¯­æ³•**</summary>

```python
from langchain.agents.middleware import after_agent, AgentState, hook_config
from langgraph.runtime import Runtime
from langchain_core.messages import AIMessage
from langchain.chat_models import init_chat_model
from typing import Any
safety_model = init_chat_model("openai:gpt-4o-mini")
@after_agent(can_jump_to=["end"])
def safety_guardrail(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:
    """Model-based guardrail: Use an LLM to evaluate response safety."""
    # Get the final AI response
    if not state["messages"]:
        return None
    last_message = state["messages"][-1]
    if not isinstance(last_message, AIMessage):
        return None
    # Use a model to evaluate safety
    safety_prompt = f"""Evaluate if this response is safe and appropriate.
    Respond with only 'SAFE' or 'UNSAFE'.
    Response: {last_message.content}"""
    result = safety_model.invoke([{"role": "user", "content": safety_prompt}])
    if "UNSAFE" in result.content:
        return {
            "messages": [{
                "role": "assistant",
                "content": "I cannot provide that response. Please rephrase your request."
            }],
            "jump_to": "end"
        }
    return None
# Use the safety guardrail
from langchain.agents import create_agent
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, calculator_tool],
    middleware=[safety_guardrail],
)
result = agent.invoke({
    "messages": [{"role": "user", "content": "How do I make explosives?"}]
})
```

</details>

### ç»„åˆå¤šä¸ªå®ˆå«

æ‚¨å¯ä»¥é€šè¿‡å°†å¤šä¸ªå®ˆå«æ·»åŠ åˆ°ä¸­é—´ä»¶æ•°ç»„ä¸­æ¥**å †å **å®ƒä»¬ã€‚å®ƒä»¬æŒ‰é¡ºåºæ‰§è¡Œï¼Œå…è®¸æ‚¨æ„å»ºåˆ†å±‚ä¿æŠ¤ï¼š

```python
from langchain.agents import create_agent
from langchain.agents.middleware import PIIMiddleware, HumanInTheLoopMiddleware
agent = create_agent(
    model="openai:gpt-4o",
    tools=[search_tool, send_email_tool],
    middleware=[
        # ç¬¬ 1 å±‚: ç¡®å®šæ€§è¾“å…¥è¿‡æ»¤å™¨ï¼ˆæ™ºèƒ½ä½“æ‰§è¡Œå‰ï¼‰
        ContentFilterMiddleware(banned_keywords=["hack", "exploit"]),
        # ç¬¬ 2 å±‚: PII ä¿æŠ¤ï¼ˆæ¨¡å‹æ‰§è¡Œå‰å’Œåï¼‰
        PIIMiddleware("email", strategy="redact", apply_to_input=True),
        PIIMiddleware("email", strategy="redact", apply_to_output=True),
        # ç¬¬ 3 å±‚: æ•æ„Ÿå·¥å…·çš„äººå·¥æ‰¹å‡†
        HumanInTheLoopMiddleware(interrupt_on={"send_email": True}),
        # ç¬¬ 4 å±‚: åŸºäºæ¨¡å‹çš„å®‰å…¨æ£€æŸ¥ï¼ˆæ™ºèƒ½ä½“æ‰§è¡Œåï¼‰
        SafetyGuardrailMiddleware(),
    ],
)
```

## é™„åŠ èµ„æº

*   [**ä¸­é—´ä»¶æ–‡æ¡£**](middleware.html) - è‡ªå®šä¹‰ä¸­é—´ä»¶çš„å®Œæ•´æŒ‡å—
*   [**ä¸­é—´ä»¶ API å‚è€ƒ**](https://reference.langchain.com/python/langchain/middleware/) - è‡ªå®šä¹‰ä¸­é—´ä»¶çš„å®Œæ•´æŒ‡å—
*   [**äººå·¥å®¡æ ¸**](human-in-the-loop.html) - ä¸ºæ•æ„Ÿæ“ä½œæ·»åŠ äººå·¥å®¡æ ¸
*   [**æµ‹è¯•æ™ºèƒ½ä½“**](test.html) - æµ‹è¯•å®‰å…¨æœºåˆ¶çš„ç­–ç•¥