import gradio as gr
import sys
import os
import time

# --- è·¯å¾„ä¿®æ­£ ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
sys.path.append(project_root)

# --- å¯¼å…¥ä¸šåŠ¡é€»è¾‘ ---
from src.app.chain import build_rag_chain
from src.ingestion.loader import DocLoader
from src.ingestion.cleaner import DataCleaner
from src.ingestion.splitter import HybridSplitter
from src.embedding.vector_db import VectorDBManager

# ==========================================
# é€»è¾‘å‡½æ•°å®šä¹‰
# ==========================================

def rebuild_index_logic(doc_path):
    if not doc_path or not os.path.exists(doc_path):
        return "âŒ é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è¾“å…¥ã€‚"
    
    try:
        yield "ğŸ“‚ [1/4] æ­£åœ¨æ‰«æåŠ è½½æ–‡æ¡£..."
        loader = DocLoader(doc_path)
        raw_docs = loader.load()
        
        yield f"ğŸ§¹ [2/4] åŠ è½½æˆåŠŸ ({len(raw_docs)}ä¸ªæ–‡ä»¶)ï¼Œæ­£åœ¨æ¸…æ´—..."
        cleaned_docs = DataCleaner.clean_documents(raw_docs)
        
        yield "âœ‚ï¸ [3/4] æ­£åœ¨è¿›è¡Œæ™ºèƒ½åˆ†å—..."
        splitter = HybridSplitter()
        chunks = splitter.split(cleaned_docs)
        
        yield f"ğŸ§  [4/4] æ­£åœ¨å‘é‡åŒ– {len(chunks)} ä¸ªç‰‡æ®µ..."
        db_manager = VectorDBManager()
        db_manager.create_index(chunks, force_rebuild=True)
        
        yield f"âœ… æˆåŠŸï¼ç´¢å¼•é‡å»ºå®Œæˆã€‚\nå…±å¤„ç† {len(chunks)} ä¸ªç‰‡æ®µã€‚"
        
    except Exception as e:
        yield f"âŒ é”™è¯¯: {str(e)}"

def chat_response_logic(message, history):
    if not message:
        return
    try:
        chain = build_rag_chain()
        partial_response = ""
        for chunk in chain.stream(message):
            partial_response += chunk
            yield partial_response
    except Exception as e:
        yield f"âš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}"

# ==========================================
# UI å¸ƒå±€æ„å»º
# ==========================================

with gr.Blocks(title="DeepSeek DevDocs RAG", theme=gr.themes.Soft()) as demo:
    
    gr.Markdown("# ğŸ“š DeepSeek å¼€å‘æ–‡æ¡£åŠ©æ‰‹ (RAG)")
    
    with gr.Row():
        # --- å·¦ä¾§ï¼šè®¾ç½®åŒº ---
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("### âš™ï¸ çŸ¥è¯†åº“ç®¡ç†")
            path_input = gr.Textbox(
                label="æ–‡æ¡£ç›®å½•è·¯å¾„",
                value="./data/raw", 
                placeholder="/path/to/docs"
            )
            rebuild_btn = gr.Button("ğŸ”„ é‡å»ºç´¢å¼•", variant="primary")
            status_output = gr.Textbox(label="ç³»ç»ŸçŠ¶æ€", value="å°±ç»ª", interactive=False, lines=4)

        # --- å³ä¾§ï¼šèŠå¤©åŒº ---
        with gr.Column(scale=4):
            # å…³é”®ä¿®æ”¹ 1: æ˜¾å¼æŒ‡å®š type="messages"
            chatbot = gr.Chatbot(
                height=700,
                avatar_images=(None, "https://img.icons8.com/color/48/bot.png"),
                label="å¯¹è¯å†å²"
            )
            
            msg = gr.Textbox(label="è¾“å…¥ä½ çš„é—®é¢˜", lines=2, autofocus=True)
            
            with gr.Row():
                clear = gr.ClearButton([msg, chatbot], value="ğŸ—‘ï¸ æ¸…é™¤å†å²")
                submit_btn = gr.Button("ğŸš€ å‘é€", variant="primary")

    # ==========================================
    # äº‹ä»¶ç»‘å®š (å…³é”®ä¿®æ”¹éƒ¨åˆ†)
    # ==========================================
    
    rebuild_btn.click(rebuild_index_logic, inputs=[path_input], outputs=[status_output])

    # å…³é”®ä¿®æ”¹ 2: é€‚é…å­—å…¸æ ¼å¼çš„ user_turn
    def user_turn(user_message, history):
        if history is None:
            history = []
        return "", history + [{"role": "user", "content": user_message}]

    # å…³é”®ä¿®æ”¹ 3: é€‚é…å­—å…¸æ ¼å¼çš„ bot_turn
    def bot_turn(history):
        # 1. è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        user_msg_data = history[-1]["content"] 
        
        # --- å…³é”®ä¿®å¤ï¼šæ¸…æ´— Gradio çš„å¤šæ¨¡æ€æ•°æ®æ ¼å¼ ---
        user_message = ""
        if isinstance(user_msg_data, str):
            user_message = user_msg_data
        elif isinstance(user_msg_data, list):
            # Gradio æ–°ç‰ˆå¯èƒ½è¿”å› [{'text': '...', 'type': 'text'}]
            for item in user_msg_data:
                if isinstance(item, dict) and item.get("type") == "text":
                    user_message = item.get("text", "")
                    break
            # å¦‚æœæ²¡æ‰¾åˆ° text å­—æ®µï¼Œå…œåº•è½¬å­—ç¬¦ä¸²
            if not user_message:
                user_message = str(user_msg_data)
        else:
            user_message = str(user_msg_data)
        # -------------------------------------------

        # 2. è¿½åŠ ä¸€ä¸ªç©ºçš„ Assistant æ¶ˆæ¯å ä½
        history.append({"role": "assistant", "content": ""})
        
        # 3. è°ƒç”¨ RAG é€»è¾‘ (ç¡®ä¿ä¼ å…¥çš„æ˜¯çº¯å­—ç¬¦ä¸²)
        generator = chat_response_logic(user_message, history[:-1])
        
        for chunk in generator:
            history[-1]["content"] = chunk
            yield history

    msg.submit(user_turn, [msg, chatbot], [msg, chatbot], queue=False).then(
        bot_turn, chatbot, chatbot
    )
    submit_btn.click(user_turn, [msg, chatbot], [msg, chatbot], queue=False).then(
        bot_turn, chatbot, chatbot
    )

if __name__ == "__main__":
    demo.queue().launch(server_name="0.0.0.0", server_port=7860, share=False)